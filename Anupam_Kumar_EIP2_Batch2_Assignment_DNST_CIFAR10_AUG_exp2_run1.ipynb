{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anupam_Kumar_EIP2_Batch2_Assignment_DNST_CIFAR10_AUG_exp2_run1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupam3693/eip2/blob/master/Anupam_Kumar_EIP2_Batch2_Assignment_DNST_CIFAR10_AUG_exp2_run1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K70hAckqg0EA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "# !pip install -q keras \n",
        "# import keras \n",
        "# print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import time\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, Callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UNHw6luQg3gc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-AphkmRV4n6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "# batch_size = 32\n",
        "# num_classes =  10\n",
        "# epochs = 50\n",
        "# l = 40\n",
        "# num_filter = 10\n",
        "# compression = 0.5\n",
        "# dropout_rate = 0\n",
        "\n",
        "batch_size = 64\n",
        "num_classes =  10\n",
        "epochs = 200\n",
        "l = 14\n",
        "num_filter = 20\n",
        "compression = 0.9\n",
        "dropout_rate = 0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoding \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter, dropout_rate):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OOP6IPsGhBwb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter, dropout_rate):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0RaKFpubhDIC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "# Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate=0.2)\n",
        "output = output_layer(Third_Transition)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "outputId": "e25a0d0c-f142-4d4f-94d3-006930feaf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 22814
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "# model.load_weights('DNST_model_weights_v6_5.h5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 32, 32, 20)   540         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 32, 32, 20)   80          conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 32, 32, 20)   0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 32, 32, 18)   3240        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 32, 32, 18)   0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 32, 32, 38)   0           conv2d_47[0][0]                  \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 32, 32, 38)   152         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 32, 32, 38)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 32, 32, 18)   6156        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 32, 32, 18)   0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 32, 32, 56)   0           concatenate_43[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 56)   224         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 32, 32, 56)   0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 32, 32, 18)   9072        activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 32, 32, 18)   0           conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 32, 32, 74)   0           concatenate_44[0][0]             \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 74)   296         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 32, 32, 74)   0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 32, 32, 18)   11988       activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 32, 32, 18)   0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 32, 32, 92)   0           concatenate_45[0][0]             \n",
            "                                                                 dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 92)   368         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 32, 32, 92)   0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 32, 32, 18)   14904       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 32, 32, 18)   0           conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 32, 32, 110)  0           concatenate_46[0][0]             \n",
            "                                                                 dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 110)  440         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 32, 32, 110)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 32, 32, 18)   17820       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 32, 32, 18)   0           conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 32, 32, 128)  0           concatenate_47[0][0]             \n",
            "                                                                 dropout_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 128)  512         concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 32, 32, 128)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 32, 32, 18)   20736       activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 32, 32, 18)   0           conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 32, 32, 146)  0           concatenate_48[0][0]             \n",
            "                                                                 dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 32, 32, 146)  584         concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 32, 32, 146)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 32, 32, 18)   23652       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 32, 32, 18)   0           conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 32, 32, 164)  0           concatenate_49[0][0]             \n",
            "                                                                 dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 32, 32, 164)  656         concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 32, 32, 164)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 32, 32, 18)   26568       activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 32, 32, 18)   0           conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 32, 32, 182)  0           concatenate_50[0][0]             \n",
            "                                                                 dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 32, 32, 182)  728         concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 32, 32, 182)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 32, 32, 18)   29484       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 32, 32, 18)   0           conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 32, 32, 200)  0           concatenate_51[0][0]             \n",
            "                                                                 dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 200)  800         concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 32, 32, 200)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 32, 32, 18)   32400       activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 32, 32, 18)   0           conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 32, 32, 218)  0           concatenate_52[0][0]             \n",
            "                                                                 dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 32, 32, 218)  872         concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 32, 32, 218)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 32, 32, 18)   35316       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 32, 32, 18)   0           conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 32, 32, 236)  0           concatenate_53[0][0]             \n",
            "                                                                 dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 32, 32, 236)  944         concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 32, 32, 236)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 32, 32, 18)   38232       activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 32, 32, 18)   0           conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 32, 32, 254)  0           concatenate_54[0][0]             \n",
            "                                                                 dropout_58[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 32, 32, 254)  1016        concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 32, 32, 254)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 32, 32, 18)   41148       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 32, 32, 18)   0           conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 32, 32, 272)  0           concatenate_55[0][0]             \n",
            "                                                                 dropout_59[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 32, 32, 272)  1088        concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 32, 32, 272)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 32, 32, 18)   4896        activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 32, 32, 18)   0           conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 16, 16, 18)   0           dropout_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 16, 16, 18)   72          average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 16, 16, 18)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 16, 16, 18)   2916        activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 16, 16, 18)   0           conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 16, 16, 36)   0           average_pooling2d_5[0][0]        \n",
            "                                                                 dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 16, 16, 36)   144         concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 16, 16, 36)   0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 16, 16, 18)   5832        activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 16, 16, 18)   0           conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 16, 16, 54)   0           concatenate_57[0][0]             \n",
            "                                                                 dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 16, 16, 54)   216         concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 16, 16, 54)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 16, 16, 18)   8748        activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 16, 16, 18)   0           conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_59 (Concatenate)    (None, 16, 16, 72)   0           concatenate_58[0][0]             \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 16, 16, 72)   288         concatenate_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 16, 16, 72)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 16, 16, 18)   11664       activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 16, 16, 18)   0           conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_60 (Concatenate)    (None, 16, 16, 90)   0           concatenate_59[0][0]             \n",
            "                                                                 dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 16, 16, 90)   360         concatenate_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 16, 16, 90)   0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 16, 16, 18)   14580       activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_65 (Dropout)            (None, 16, 16, 18)   0           conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 16, 16, 108)  0           concatenate_60[0][0]             \n",
            "                                                                 dropout_65[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 16, 16, 108)  432         concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 16, 16, 108)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 16, 16, 18)   17496       activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_66 (Dropout)            (None, 16, 16, 18)   0           conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 16, 16, 126)  0           concatenate_61[0][0]             \n",
            "                                                                 dropout_66[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 16, 16, 126)  504         concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 16, 16, 126)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 16, 16, 18)   20412       activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_67 (Dropout)            (None, 16, 16, 18)   0           conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_63 (Concatenate)    (None, 16, 16, 144)  0           concatenate_62[0][0]             \n",
            "                                                                 dropout_67[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 16, 16, 144)  576         concatenate_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 16, 16, 144)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 16, 16, 18)   23328       activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_68 (Dropout)            (None, 16, 16, 18)   0           conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_64 (Concatenate)    (None, 16, 16, 162)  0           concatenate_63[0][0]             \n",
            "                                                                 dropout_68[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 16, 16, 162)  648         concatenate_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 16, 16, 162)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 16, 16, 18)   26244       activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_69 (Dropout)            (None, 16, 16, 18)   0           conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_65 (Concatenate)    (None, 16, 16, 180)  0           concatenate_64[0][0]             \n",
            "                                                                 dropout_69[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 16, 16, 180)  720         concatenate_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 16, 16, 180)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 16, 16, 18)   29160       activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_70 (Dropout)            (None, 16, 16, 18)   0           conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 16, 16, 198)  0           concatenate_65[0][0]             \n",
            "                                                                 dropout_70[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 16, 16, 198)  792         concatenate_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 16, 16, 198)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 16, 16, 18)   32076       activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_71 (Dropout)            (None, 16, 16, 18)   0           conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 16, 16, 216)  0           concatenate_66[0][0]             \n",
            "                                                                 dropout_71[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 16, 16, 216)  864         concatenate_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 16, 16, 216)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 16, 16, 18)   34992       activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_72 (Dropout)            (None, 16, 16, 18)   0           conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_68 (Concatenate)    (None, 16, 16, 234)  0           concatenate_67[0][0]             \n",
            "                                                                 dropout_72[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 16, 16, 234)  936         concatenate_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 16, 16, 234)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 16, 16, 18)   37908       activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_73 (Dropout)            (None, 16, 16, 18)   0           conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_69 (Concatenate)    (None, 16, 16, 252)  0           concatenate_68[0][0]             \n",
            "                                                                 dropout_73[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 16, 16, 252)  1008        concatenate_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 16, 16, 252)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 16, 16, 18)   40824       activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_74 (Dropout)            (None, 16, 16, 18)   0           conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_70 (Concatenate)    (None, 16, 16, 270)  0           concatenate_69[0][0]             \n",
            "                                                                 dropout_74[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 16, 16, 270)  1080        concatenate_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 16, 16, 270)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 16, 16, 18)   4860        activation_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 16, 16, 18)   0           conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 8, 8, 18)     0           dropout_75[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 18)     72          average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 18)     0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 18)     2916        activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_76 (Dropout)            (None, 8, 8, 18)     0           conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_71 (Concatenate)    (None, 8, 8, 36)     0           average_pooling2d_6[0][0]        \n",
            "                                                                 dropout_76[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 36)     144         concatenate_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 36)     0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 18)     5832        activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_77 (Dropout)            (None, 8, 8, 18)     0           conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_72 (Concatenate)    (None, 8, 8, 54)     0           concatenate_71[0][0]             \n",
            "                                                                 dropout_77[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 54)     216         concatenate_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 54)     0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 18)     8748        activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_78 (Dropout)            (None, 8, 8, 18)     0           conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_73 (Concatenate)    (None, 8, 8, 72)     0           concatenate_72[0][0]             \n",
            "                                                                 dropout_78[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 72)     288         concatenate_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 72)     0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 18)     11664       activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_79 (Dropout)            (None, 8, 8, 18)     0           conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_74 (Concatenate)    (None, 8, 8, 90)     0           concatenate_73[0][0]             \n",
            "                                                                 dropout_79[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 90)     360         concatenate_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 90)     0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 18)     14580       activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_80 (Dropout)            (None, 8, 8, 18)     0           conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_75 (Concatenate)    (None, 8, 8, 108)    0           concatenate_74[0][0]             \n",
            "                                                                 dropout_80[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 108)    432         concatenate_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 108)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 18)     17496       activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_81 (Dropout)            (None, 8, 8, 18)     0           conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_76 (Concatenate)    (None, 8, 8, 126)    0           concatenate_75[0][0]             \n",
            "                                                                 dropout_81[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 126)    504         concatenate_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 126)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 18)     20412       activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_82 (Dropout)            (None, 8, 8, 18)     0           conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 8, 8, 144)    0           concatenate_76[0][0]             \n",
            "                                                                 dropout_82[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 144)    576         concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 144)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 18)     23328       activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_83 (Dropout)            (None, 8, 8, 18)     0           conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 8, 8, 162)    0           concatenate_77[0][0]             \n",
            "                                                                 dropout_83[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 162)    648         concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 162)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 18)     26244       activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 8, 8, 18)     0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 8, 8, 180)    0           concatenate_78[0][0]             \n",
            "                                                                 dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 180)    720         concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 180)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 18)     29160       activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 8, 8, 18)     0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 8, 8, 198)    0           concatenate_79[0][0]             \n",
            "                                                                 dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 198)    792         concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 198)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 18)     32076       activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 8, 8, 18)     0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 8, 8, 216)    0           concatenate_80[0][0]             \n",
            "                                                                 dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 216)    864         concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 216)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 18)     34992       activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 8, 8, 18)     0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 8, 8, 234)    0           concatenate_81[0][0]             \n",
            "                                                                 dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 234)    936         concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 234)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 18)     37908       activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 8, 8, 18)     0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 8, 8, 252)    0           concatenate_82[0][0]             \n",
            "                                                                 dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 252)    1008        concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 252)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 18)     40824       activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 8, 8, 18)     0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 8, 8, 270)    0           concatenate_83[0][0]             \n",
            "                                                                 dropout_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 270)    1080        concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 270)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 18)     4860        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, 8, 8, 18)     0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 4, 4, 18)     0           dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 4, 4, 18)     72          average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 4, 4, 18)     0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 2, 2, 18)     0           activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 72)           0           average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           730         flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 965,074\n",
            "Trainable params: 952,018\n",
            "Non-trainable params: 13,056\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kIssxPt94n6b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ak - block 3 learning rate\n",
        "\n",
        "from keras.callbacks import *\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
        "    The method cycles the learning rate between two boundaries with\n",
        "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
        "    The amplitude of the cycle can be scaled on a per-iteration or \n",
        "    per-cycle basis.\n",
        "    This class has three built-in policies, as put forth in the paper.\n",
        "    \"triangular\":\n",
        "        A basic triangular cycle w/ no amplitude scaling.\n",
        "    \"triangular2\":\n",
        "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
        "    \"exp_range\":\n",
        "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
        "        cycle iteration.\n",
        "    For more detail, please see paper.\n",
        "    \n",
        "    # Example\n",
        "        ```python\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., mode='triangular')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```\n",
        "    \n",
        "    Class also supports custom scaling functions:\n",
        "        ```python\n",
        "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "            model.fit(X_train, Y_train, callbacks=[clr])\n",
        "        ```    \n",
        "    # Arguments\n",
        "        base_lr: initial learning rate which is the\n",
        "            lower boundary in the cycle.\n",
        "        max_lr: upper boundary in the cycle. Functionally,\n",
        "            it defines the cycle amplitude (max_lr - base_lr).\n",
        "            The lr at any cycle is the sum of base_lr\n",
        "            and some scaling of the amplitude; therefore \n",
        "            max_lr may not actually be reached depending on\n",
        "            scaling function.\n",
        "        step_size: number of training iterations per\n",
        "            half cycle. Authors suggest setting step_size\n",
        "            2-8 x training iterations in epoch.\n",
        "        mode: one of {triangular, triangular2, exp_range}.\n",
        "            Default 'triangular'.\n",
        "            Values correspond to policies detailed above.\n",
        "            If scale_fn is not None, this argument is ignored.\n",
        "        gamma: constant in 'exp_range' scaling function:\n",
        "            gamma**(cycle iterations)\n",
        "        scale_fn: Custom scaling policy defined by a single\n",
        "            argument lambda function, where \n",
        "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
        "            mode paramater is ignored \n",
        "        scale_mode: {'cycle', 'iterations'}.\n",
        "            Defines whether scale_fn is evaluated on \n",
        "            cycle number or cycle iterations (training\n",
        "            iterations since start of cycle). Default is 'cycle'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "            \n",
        "clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
        "clr = CyclicLR(base_lr=0.1, max_lr=0.3,\n",
        "                                step_size=2000., scale_fn=clr_fn,\n",
        "                                scale_mode='cycle')\n",
        "\n",
        "\n",
        "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0.5, patience=100, verbose=1,mode='min')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b4XOsW3ahSkL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "# decay=10e-4,momentum=0.9\n",
        "sgd = SGD(decay=10e-4,momentum=0.9)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ep1v_RxxdR-h",
        "colab": {},
        "outputId": "8fb4c7d0-2644-41c0-8da5-df30f5b8b4e0"
      },
      "cell_type": "code",
      "source": [
        "# ak - block 4 - image aug\n",
        "\n",
        "# we can compare the performance with or without data augmentation\n",
        "data_augmentation = True\n",
        "callbacks_list=[clr,earlystopper]\n",
        "\n",
        "start = time.time()\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model_info = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test, y_test),\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks_list\n",
        "        )\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by dataset std\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in 0 to 180 degrees\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    \n",
        "    model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=2*(x_train.shape[0]//batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        callbacks=callbacks_list\n",
        "                       )\n",
        "\n",
        "end = time.time()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/200\n",
            "   3/1562 [..............................] - ETA: 50:08 - loss: 2.4828 - acc: 0.0938  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.112095). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 169s 108ms/step - loss: 1.3766 - acc: 0.4978 - val_loss: 1.5768 - val_acc: 0.5614\n",
            "Epoch 2/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.9242 - acc: 0.6715 - val_loss: 0.9718 - val_acc: 0.6975\n",
            "Epoch 3/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.7146 - acc: 0.7496 - val_loss: 0.7881 - val_acc: 0.7596\n",
            "Epoch 4/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.6719 - acc: 0.7648 - val_loss: 0.8145 - val_acc: 0.7579\n",
            "Epoch 5/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.5982 - acc: 0.7923 - val_loss: 0.8020 - val_acc: 0.7657\n",
            "Epoch 6/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.5276 - acc: 0.8176 - val_loss: 0.6271 - val_acc: 0.8111\n",
            "Epoch 7/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.5003 - acc: 0.8274 - val_loss: 0.6912 - val_acc: 0.7965\n",
            "Epoch 8/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.4807 - acc: 0.8337 - val_loss: 0.8582 - val_acc: 0.7630\n",
            "Epoch 9/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.4989 - acc: 0.8270 - val_loss: 0.8618 - val_acc: 0.7628\n",
            "Epoch 10/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.4682 - acc: 0.8375 - val_loss: 0.5251 - val_acc: 0.8417\n",
            "Epoch 11/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.4412 - acc: 0.8471 - val_loss: 0.7256 - val_acc: 0.7804\n",
            "Epoch 12/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.4792 - acc: 0.8345 - val_loss: 0.7727 - val_acc: 0.7973\n",
            "Epoch 13/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.4002 - acc: 0.8621 - val_loss: 0.5854 - val_acc: 0.8400\n",
            "Epoch 14/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.3870 - acc: 0.8656 - val_loss: 0.5317 - val_acc: 0.8466\n",
            "Epoch 15/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.3777 - acc: 0.8688 - val_loss: 0.6208 - val_acc: 0.8359\n",
            "Epoch 16/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.3339 - acc: 0.8845 - val_loss: 0.5122 - val_acc: 0.8598\n",
            "Epoch 17/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.3218 - acc: 0.8874 - val_loss: 0.6193 - val_acc: 0.8359\n",
            "Epoch 18/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.3149 - acc: 0.8892 - val_loss: 0.3980 - val_acc: 0.8793\n",
            "Epoch 19/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.3292 - acc: 0.8855 - val_loss: 0.5931 - val_acc: 0.8372\n",
            "Epoch 20/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.3391 - acc: 0.8817 - val_loss: 0.4467 - val_acc: 0.8714\n",
            "Epoch 21/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.3041 - acc: 0.8933 - val_loss: 0.5723 - val_acc: 0.8513\n",
            "Epoch 22/200\n",
            "1562/1562 [==============================] - 164s 105ms/step - loss: 0.3541 - acc: 0.8776 - val_loss: 0.5239 - val_acc: 0.8573\n",
            "Epoch 23/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.3164 - acc: 0.8901 - val_loss: 0.4525 - val_acc: 0.8774\n",
            "Epoch 24/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2800 - acc: 0.9028 - val_loss: 0.5701 - val_acc: 0.8560\n",
            "Epoch 25/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2966 - acc: 0.8964 - val_loss: 0.6719 - val_acc: 0.8354\n",
            "Epoch 26/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2592 - acc: 0.9099 - val_loss: 0.4533 - val_acc: 0.8785\n",
            "Epoch 27/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.2449 - acc: 0.9146 - val_loss: 0.4033 - val_acc: 0.8880\n",
            "Epoch 28/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2426 - acc: 0.9156 - val_loss: 0.5021 - val_acc: 0.8709\n",
            "Epoch 29/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2474 - acc: 0.9136 - val_loss: 0.5203 - val_acc: 0.8726\n",
            "Epoch 30/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2699 - acc: 0.9051 - val_loss: 0.7217 - val_acc: 0.8303\n",
            "Epoch 31/200\n",
            "1562/1562 [==============================] - 164s 105ms/step - loss: 0.2393 - acc: 0.9168 - val_loss: 0.4764 - val_acc: 0.8746\n",
            "Epoch 32/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2774 - acc: 0.9032 - val_loss: 0.8181 - val_acc: 0.8116\n",
            "Epoch 33/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2768 - acc: 0.9029 - val_loss: 0.3997 - val_acc: 0.8933\n",
            "Epoch 34/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2289 - acc: 0.9199 - val_loss: 0.4341 - val_acc: 0.8880\n",
            "Epoch 35/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2424 - acc: 0.9138 - val_loss: 0.4442 - val_acc: 0.8889\n",
            "Epoch 36/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2208 - acc: 0.9231 - val_loss: 0.4206 - val_acc: 0.8910\n",
            "Epoch 37/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2017 - acc: 0.9288 - val_loss: 0.4246 - val_acc: 0.8943\n",
            "Epoch 38/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1961 - acc: 0.9309 - val_loss: 0.4447 - val_acc: 0.8894\n",
            "Epoch 39/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1962 - acc: 0.9302 - val_loss: 0.4482 - val_acc: 0.8916\n",
            "Epoch 40/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2229 - acc: 0.9215 - val_loss: 0.5278 - val_acc: 0.8674\n",
            "Epoch 41/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2062 - acc: 0.9271 - val_loss: 0.4095 - val_acc: 0.8986\n",
            "Epoch 42/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.2173 - acc: 0.9229 - val_loss: 0.5784 - val_acc: 0.8546\n",
            "Epoch 43/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2477 - acc: 0.9133 - val_loss: 0.4653 - val_acc: 0.8816\n",
            "Epoch 44/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1959 - acc: 0.9311 - val_loss: 0.4446 - val_acc: 0.8985\n",
            "Epoch 45/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2028 - acc: 0.9288 - val_loss: 0.4117 - val_acc: 0.8907\n",
            "Epoch 46/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1932 - acc: 0.9314 - val_loss: 0.4438 - val_acc: 0.8954\n",
            "Epoch 47/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1711 - acc: 0.9388 - val_loss: 0.3780 - val_acc: 0.9081\n",
            "Epoch 48/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1672 - acc: 0.9417 - val_loss: 0.4596 - val_acc: 0.8911\n",
            "Epoch 49/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1642 - acc: 0.9421 - val_loss: 0.4310 - val_acc: 0.8977\n",
            "Epoch 50/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1868 - acc: 0.9334 - val_loss: 0.6245 - val_acc: 0.8647\n",
            "Epoch 51/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1837 - acc: 0.9349 - val_loss: 0.3743 - val_acc: 0.9075\n",
            "Epoch 52/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1785 - acc: 0.9377 - val_loss: 0.7126 - val_acc: 0.8555\n",
            "Epoch 53/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.2202 - acc: 0.9225 - val_loss: 0.5612 - val_acc: 0.8719\n",
            "Epoch 54/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1776 - acc: 0.9376 - val_loss: 0.4087 - val_acc: 0.9039\n",
            "Epoch 55/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1698 - acc: 0.9403 - val_loss: 0.4378 - val_acc: 0.8930\n",
            "Epoch 56/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1782 - acc: 0.9370 - val_loss: 0.3986 - val_acc: 0.9035\n",
            "Epoch 57/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1501 - acc: 0.9473 - val_loss: 0.3838 - val_acc: 0.9078\n",
            "Epoch 58/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1426 - acc: 0.9487 - val_loss: 0.4533 - val_acc: 0.8949\n",
            "Epoch 59/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1417 - acc: 0.9497 - val_loss: 0.4213 - val_acc: 0.9034\n",
            "Epoch 60/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1547 - acc: 0.9450 - val_loss: 0.4899 - val_acc: 0.8878\n",
            "Epoch 61/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1680 - acc: 0.9406 - val_loss: 0.4674 - val_acc: 0.8945\n",
            "Epoch 62/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1478 - acc: 0.9476 - val_loss: 0.5168 - val_acc: 0.8878\n",
            "Epoch 63/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1927 - acc: 0.9314 - val_loss: 0.4949 - val_acc: 0.8797\n",
            "Epoch 64/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1688 - acc: 0.9404 - val_loss: 0.4029 - val_acc: 0.9036\n",
            "Epoch 65/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1459 - acc: 0.9480 - val_loss: 0.4492 - val_acc: 0.8981\n",
            "Epoch 66/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1605 - acc: 0.9441 - val_loss: 0.4292 - val_acc: 0.8993\n",
            "Epoch 67/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1354 - acc: 0.9522 - val_loss: 0.4334 - val_acc: 0.9033\n",
            "Epoch 68/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1255 - acc: 0.9554 - val_loss: 0.4020 - val_acc: 0.9105\n",
            "Epoch 69/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1212 - acc: 0.9564 - val_loss: 0.4123 - val_acc: 0.9112\n",
            "Epoch 70/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1323 - acc: 0.9524 - val_loss: 0.4803 - val_acc: 0.8947\n",
            "Epoch 71/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1548 - acc: 0.9452 - val_loss: 0.3825 - val_acc: 0.9064\n",
            "Epoch 72/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1308 - acc: 0.9540 - val_loss: 0.5177 - val_acc: 0.8911\n",
            "Epoch 73/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1612 - acc: 0.9423 - val_loss: 0.4958 - val_acc: 0.8909\n",
            "Epoch 74/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1654 - acc: 0.9420 - val_loss: 0.4658 - val_acc: 0.8922\n",
            "Epoch 75/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1272 - acc: 0.9548 - val_loss: 0.4761 - val_acc: 0.8940\n",
            "Epoch 76/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1416 - acc: 0.9496 - val_loss: 0.4901 - val_acc: 0.9001\n",
            "Epoch 77/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1244 - acc: 0.9559 - val_loss: 0.3738 - val_acc: 0.9154\n",
            "Epoch 78/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1121 - acc: 0.9600 - val_loss: 0.4354 - val_acc: 0.9116\n",
            "Epoch 79/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1095 - acc: 0.9606 - val_loss: 0.5082 - val_acc: 0.8985\n",
            "Epoch 80/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1121 - acc: 0.9598 - val_loss: 0.5096 - val_acc: 0.9016\n",
            "Epoch 81/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1397 - acc: 0.9507 - val_loss: 0.4807 - val_acc: 0.8978\n",
            "Epoch 82/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1238 - acc: 0.9564 - val_loss: 0.3829 - val_acc: 0.9137\n",
            "Epoch 83/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1335 - acc: 0.9517 - val_loss: 0.5246 - val_acc: 0.8945\n",
            "Epoch 84/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1605 - acc: 0.9434 - val_loss: 0.4478 - val_acc: 0.8978\n",
            "Epoch 85/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1169 - acc: 0.9575 - val_loss: 0.4256 - val_acc: 0.9104\n",
            "Epoch 86/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1289 - acc: 0.9541 - val_loss: 0.5311 - val_acc: 0.8881\n",
            "Epoch 87/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1189 - acc: 0.9579 - val_loss: 0.4460 - val_acc: 0.9067\n",
            "Epoch 88/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1055 - acc: 0.9623 - val_loss: 0.4173 - val_acc: 0.9159\n",
            "Epoch 89/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0978 - acc: 0.9647 - val_loss: 0.4737 - val_acc: 0.9088\n",
            "Epoch 90/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0999 - acc: 0.9642 - val_loss: 0.4715 - val_acc: 0.9069\n",
            "Epoch 91/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1181 - acc: 0.9574 - val_loss: 0.5598 - val_acc: 0.8835\n",
            "Epoch 92/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1205 - acc: 0.9559 - val_loss: 0.4112 - val_acc: 0.9130\n",
            "Epoch 93/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1090 - acc: 0.9612 - val_loss: 0.5451 - val_acc: 0.8913\n",
            "Epoch 94/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1522 - acc: 0.9459 - val_loss: 0.4706 - val_acc: 0.8964\n",
            "Epoch 95/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1172 - acc: 0.9589 - val_loss: 0.3850 - val_acc: 0.9182\n",
            "Epoch 96/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1131 - acc: 0.9603 - val_loss: 0.4253 - val_acc: 0.9095\n",
            "Epoch 97/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1167 - acc: 0.9590 - val_loss: 0.4478 - val_acc: 0.9117\n",
            "Epoch 98/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0958 - acc: 0.9662 - val_loss: 0.3999 - val_acc: 0.9169\n",
            "Epoch 99/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0914 - acc: 0.9676 - val_loss: 0.4015 - val_acc: 0.9183\n",
            "Epoch 100/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0884 - acc: 0.9682 - val_loss: 0.4419 - val_acc: 0.9151\n",
            "Epoch 101/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1031 - acc: 0.9636 - val_loss: 0.4002 - val_acc: 0.9137\n",
            "Epoch 102/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1126 - acc: 0.9598 - val_loss: 0.3982 - val_acc: 0.9163\n",
            "Epoch 103/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0980 - acc: 0.9657 - val_loss: 0.5017 - val_acc: 0.9030\n",
            "Epoch 104/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1377 - acc: 0.9505 - val_loss: 0.6081 - val_acc: 0.8711\n",
            "Epoch 105/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1172 - acc: 0.9582 - val_loss: 0.4598 - val_acc: 0.9034\n",
            "Epoch 106/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1007 - acc: 0.9642 - val_loss: 0.4554 - val_acc: 0.9078\n",
            "Epoch 107/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1086 - acc: 0.9615 - val_loss: 0.4296 - val_acc: 0.9134\n",
            "Epoch 108/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0894 - acc: 0.9676 - val_loss: 0.4095 - val_acc: 0.9200\n",
            "Epoch 109/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.0846 - acc: 0.9699 - val_loss: 0.3987 - val_acc: 0.9198\n",
            "Epoch 110/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0828 - acc: 0.9708 - val_loss: 0.4266 - val_acc: 0.9147\n",
            "Epoch 111/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.0886 - acc: 0.9687 - val_loss: 0.5398 - val_acc: 0.9021\n",
            "Epoch 112/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1041 - acc: 0.9633 - val_loss: 0.4299 - val_acc: 0.9179\n",
            "Epoch 113/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.0870 - acc: 0.9690 - val_loss: 0.4453 - val_acc: 0.9108\n",
            "Epoch 114/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1190 - acc: 0.9582 - val_loss: 0.5011 - val_acc: 0.8920\n",
            "Epoch 115/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.1202 - acc: 0.9572 - val_loss: 0.3890 - val_acc: 0.9164\n",
            "Epoch 116/200\n",
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.0894 - acc: 0.9684 - val_loss: 0.4534 - val_acc: 0.9089\n",
            "Epoch 117/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 163s 104ms/step - loss: 0.1018 - acc: 0.9636 - val_loss: 0.4176 - val_acc: 0.9142\n",
            "Epoch 118/200\n",
            "1562/1562 [==============================] - 162s 104ms/step - loss: 0.0888 - acc: 0.9687 - val_loss: 0.4309 - val_acc: 0.9134\n",
            "Epoch 00118: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gPlro5VY4n6k",
        "colab_type": "code",
        "colab": {},
        "outputId": "df9227e5-6179-4f8f-88e3-54125b4e5783"
      },
      "cell_type": "code",
      "source": [
        "print (\"Model took %0.2f hours to train\"%((end - start)/3600))\n",
        "\n",
        "plot_model_history(model_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model took 5.34 hours to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZcWydmIVhZGr",
        "outputId": "4155982a-83c7-4775-f31f-bcbeaa22309b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 5s 525us/step\n",
            "Test loss: 0.4309173761647195\n",
            "Test accuracy: 0.9134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UE3lF6EH1r_L",
        "outputId": "56ded1ff-0d18-4299-dadd-cc9d7005acea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model_weights_s2_v1.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Og56VCRh5j8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}