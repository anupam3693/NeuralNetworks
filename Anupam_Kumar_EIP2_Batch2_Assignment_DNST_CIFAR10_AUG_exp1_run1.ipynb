{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anupam_Kumar_EIP2_Batch2_Assignment_DNST_CIFAR10_AUG_exp1_run1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anupam3693/eip2/blob/master/Anupam_Kumar_EIP2_Batch2_Assignment_DNST_CIFAR10_AUG_exp1_run1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K70hAckqg0EA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "# !pip install -q keras \n",
        "# import keras \n",
        "# print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import time\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, Callback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UNHw6luQg3gc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueIiGYwjJKz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "# batch_size = 32\n",
        "# num_classes =  10\n",
        "# epochs = 50\n",
        "# l = 40\n",
        "# num_filter = 10\n",
        "# compression = 0.5\n",
        "# dropout_rate = 0\n",
        "\n",
        "batch_size = 64\n",
        "num_classes =  10\n",
        "epochs = 200\n",
        "l = 20\n",
        "num_filter = 28\n",
        "compression = 0.9\n",
        "dropout_rate = 0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoding \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        " \n",
        "# #z-score\n",
        "# mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "# std = np.std(x_train,axis=(0,1,2,3))\n",
        "# x_train = (x_train-mean)/(std+1e-7)\n",
        "# x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter, dropout_rate):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        Dense_Conv2D_1_1 = Conv2D(num_filter, (1,1), use_bias=False ,padding='same')(temp)\n",
        "        BatchNorm = BatchNormalization()(Dense_Conv2D_1_1)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OOP6IPsGhBwb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter, dropout_rate):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0RaKFpubhDIC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "# Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate=0.2)\n",
        "output = output_layer(Third_Transition)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "outputId": "e25a0d0c-f142-4d4f-94d3-006930feaf26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 22814
        }
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "# model.load_weights('v7_7_1_weights.06-0.37--0.91.hdf5')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1123 (Conv2D)            (None, 32, 32, 28)   756         input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1124 (Conv2D)            (None, 32, 32, 28)   784         conv2d_1123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_601 (BatchN (None, 32, 32, 28)   112         conv2d_1124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_601 (Activation)     (None, 32, 32, 28)   0           batch_normalization_601[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1125 (Conv2D)            (None, 32, 32, 25)   6300        activation_601[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_592 (Dropout)           (None, 32, 32, 25)   0           conv2d_1125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_563 (Concatenate)   (None, 32, 32, 53)   0           conv2d_1123[0][0]                \n",
            "                                                                 dropout_592[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1126 (Conv2D)            (None, 32, 32, 28)   1484        concatenate_563[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_602 (BatchN (None, 32, 32, 28)   112         conv2d_1126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_602 (Activation)     (None, 32, 32, 28)   0           batch_normalization_602[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1127 (Conv2D)            (None, 32, 32, 25)   6300        activation_602[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_593 (Dropout)           (None, 32, 32, 25)   0           conv2d_1127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_564 (Concatenate)   (None, 32, 32, 78)   0           concatenate_563[0][0]            \n",
            "                                                                 dropout_593[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1128 (Conv2D)            (None, 32, 32, 28)   2184        concatenate_564[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_603 (BatchN (None, 32, 32, 28)   112         conv2d_1128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_603 (Activation)     (None, 32, 32, 28)   0           batch_normalization_603[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1129 (Conv2D)            (None, 32, 32, 25)   6300        activation_603[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_594 (Dropout)           (None, 32, 32, 25)   0           conv2d_1129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_565 (Concatenate)   (None, 32, 32, 103)  0           concatenate_564[0][0]            \n",
            "                                                                 dropout_594[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1130 (Conv2D)            (None, 32, 32, 28)   2884        concatenate_565[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_604 (BatchN (None, 32, 32, 28)   112         conv2d_1130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_604 (Activation)     (None, 32, 32, 28)   0           batch_normalization_604[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1131 (Conv2D)            (None, 32, 32, 25)   6300        activation_604[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_595 (Dropout)           (None, 32, 32, 25)   0           conv2d_1131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_566 (Concatenate)   (None, 32, 32, 128)  0           concatenate_565[0][0]            \n",
            "                                                                 dropout_595[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1132 (Conv2D)            (None, 32, 32, 28)   3584        concatenate_566[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_605 (BatchN (None, 32, 32, 28)   112         conv2d_1132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_605 (Activation)     (None, 32, 32, 28)   0           batch_normalization_605[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1133 (Conv2D)            (None, 32, 32, 25)   6300        activation_605[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_596 (Dropout)           (None, 32, 32, 25)   0           conv2d_1133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_567 (Concatenate)   (None, 32, 32, 153)  0           concatenate_566[0][0]            \n",
            "                                                                 dropout_596[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1134 (Conv2D)            (None, 32, 32, 28)   4284        concatenate_567[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_606 (BatchN (None, 32, 32, 28)   112         conv2d_1134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_606 (Activation)     (None, 32, 32, 28)   0           batch_normalization_606[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1135 (Conv2D)            (None, 32, 32, 25)   6300        activation_606[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_597 (Dropout)           (None, 32, 32, 25)   0           conv2d_1135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_568 (Concatenate)   (None, 32, 32, 178)  0           concatenate_567[0][0]            \n",
            "                                                                 dropout_597[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1136 (Conv2D)            (None, 32, 32, 28)   4984        concatenate_568[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_607 (BatchN (None, 32, 32, 28)   112         conv2d_1136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_607 (Activation)     (None, 32, 32, 28)   0           batch_normalization_607[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1137 (Conv2D)            (None, 32, 32, 25)   6300        activation_607[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_598 (Dropout)           (None, 32, 32, 25)   0           conv2d_1137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_569 (Concatenate)   (None, 32, 32, 203)  0           concatenate_568[0][0]            \n",
            "                                                                 dropout_598[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1138 (Conv2D)            (None, 32, 32, 28)   5684        concatenate_569[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_608 (BatchN (None, 32, 32, 28)   112         conv2d_1138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_608 (Activation)     (None, 32, 32, 28)   0           batch_normalization_608[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1139 (Conv2D)            (None, 32, 32, 25)   6300        activation_608[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_599 (Dropout)           (None, 32, 32, 25)   0           conv2d_1139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_570 (Concatenate)   (None, 32, 32, 228)  0           concatenate_569[0][0]            \n",
            "                                                                 dropout_599[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1140 (Conv2D)            (None, 32, 32, 28)   6384        concatenate_570[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_609 (BatchN (None, 32, 32, 28)   112         conv2d_1140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_609 (Activation)     (None, 32, 32, 28)   0           batch_normalization_609[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1141 (Conv2D)            (None, 32, 32, 25)   6300        activation_609[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_600 (Dropout)           (None, 32, 32, 25)   0           conv2d_1141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_571 (Concatenate)   (None, 32, 32, 253)  0           concatenate_570[0][0]            \n",
            "                                                                 dropout_600[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1142 (Conv2D)            (None, 32, 32, 28)   7084        concatenate_571[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_610 (BatchN (None, 32, 32, 28)   112         conv2d_1142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_610 (Activation)     (None, 32, 32, 28)   0           batch_normalization_610[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1143 (Conv2D)            (None, 32, 32, 25)   6300        activation_610[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_601 (Dropout)           (None, 32, 32, 25)   0           conv2d_1143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_572 (Concatenate)   (None, 32, 32, 278)  0           concatenate_571[0][0]            \n",
            "                                                                 dropout_601[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1144 (Conv2D)            (None, 32, 32, 28)   7784        concatenate_572[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_611 (BatchN (None, 32, 32, 28)   112         conv2d_1144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_611 (Activation)     (None, 32, 32, 28)   0           batch_normalization_611[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1145 (Conv2D)            (None, 32, 32, 25)   6300        activation_611[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_602 (Dropout)           (None, 32, 32, 25)   0           conv2d_1145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_573 (Concatenate)   (None, 32, 32, 303)  0           concatenate_572[0][0]            \n",
            "                                                                 dropout_602[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1146 (Conv2D)            (None, 32, 32, 28)   8484        concatenate_573[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_612 (BatchN (None, 32, 32, 28)   112         conv2d_1146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_612 (Activation)     (None, 32, 32, 28)   0           batch_normalization_612[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1147 (Conv2D)            (None, 32, 32, 25)   6300        activation_612[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_603 (Dropout)           (None, 32, 32, 25)   0           conv2d_1147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_574 (Concatenate)   (None, 32, 32, 328)  0           concatenate_573[0][0]            \n",
            "                                                                 dropout_603[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1148 (Conv2D)            (None, 32, 32, 28)   9184        concatenate_574[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_613 (BatchN (None, 32, 32, 28)   112         conv2d_1148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_613 (Activation)     (None, 32, 32, 28)   0           batch_normalization_613[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1149 (Conv2D)            (None, 32, 32, 25)   6300        activation_613[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_604 (Dropout)           (None, 32, 32, 25)   0           conv2d_1149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_575 (Concatenate)   (None, 32, 32, 353)  0           concatenate_574[0][0]            \n",
            "                                                                 dropout_604[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1150 (Conv2D)            (None, 32, 32, 28)   9884        concatenate_575[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_614 (BatchN (None, 32, 32, 28)   112         conv2d_1150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_614 (Activation)     (None, 32, 32, 28)   0           batch_normalization_614[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1151 (Conv2D)            (None, 32, 32, 25)   6300        activation_614[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_605 (Dropout)           (None, 32, 32, 25)   0           conv2d_1151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_576 (Concatenate)   (None, 32, 32, 378)  0           concatenate_575[0][0]            \n",
            "                                                                 dropout_605[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1152 (Conv2D)            (None, 32, 32, 28)   10584       concatenate_576[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_615 (BatchN (None, 32, 32, 28)   112         conv2d_1152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_615 (Activation)     (None, 32, 32, 28)   0           batch_normalization_615[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1153 (Conv2D)            (None, 32, 32, 25)   6300        activation_615[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_606 (Dropout)           (None, 32, 32, 25)   0           conv2d_1153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_577 (Concatenate)   (None, 32, 32, 403)  0           concatenate_576[0][0]            \n",
            "                                                                 dropout_606[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1154 (Conv2D)            (None, 32, 32, 28)   11284       concatenate_577[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_616 (BatchN (None, 32, 32, 28)   112         conv2d_1154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_616 (Activation)     (None, 32, 32, 28)   0           batch_normalization_616[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1155 (Conv2D)            (None, 32, 32, 25)   6300        activation_616[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_607 (Dropout)           (None, 32, 32, 25)   0           conv2d_1155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_578 (Concatenate)   (None, 32, 32, 428)  0           concatenate_577[0][0]            \n",
            "                                                                 dropout_607[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1156 (Conv2D)            (None, 32, 32, 28)   11984       concatenate_578[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_617 (BatchN (None, 32, 32, 28)   112         conv2d_1156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_617 (Activation)     (None, 32, 32, 28)   0           batch_normalization_617[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1157 (Conv2D)            (None, 32, 32, 25)   6300        activation_617[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_608 (Dropout)           (None, 32, 32, 25)   0           conv2d_1157[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_579 (Concatenate)   (None, 32, 32, 453)  0           concatenate_578[0][0]            \n",
            "                                                                 dropout_608[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1158 (Conv2D)            (None, 32, 32, 28)   12684       concatenate_579[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_618 (BatchN (None, 32, 32, 28)   112         conv2d_1158[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_618 (Activation)     (None, 32, 32, 28)   0           batch_normalization_618[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1159 (Conv2D)            (None, 32, 32, 25)   6300        activation_618[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_609 (Dropout)           (None, 32, 32, 25)   0           conv2d_1159[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_580 (Concatenate)   (None, 32, 32, 478)  0           concatenate_579[0][0]            \n",
            "                                                                 dropout_609[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1160 (Conv2D)            (None, 32, 32, 28)   13384       concatenate_580[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_619 (BatchN (None, 32, 32, 28)   112         conv2d_1160[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_619 (Activation)     (None, 32, 32, 28)   0           batch_normalization_619[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1161 (Conv2D)            (None, 32, 32, 25)   6300        activation_619[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_610 (Dropout)           (None, 32, 32, 25)   0           conv2d_1161[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_581 (Concatenate)   (None, 32, 32, 503)  0           concatenate_580[0][0]            \n",
            "                                                                 dropout_610[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1162 (Conv2D)            (None, 32, 32, 28)   14084       concatenate_581[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_620 (BatchN (None, 32, 32, 28)   112         conv2d_1162[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_620 (Activation)     (None, 32, 32, 28)   0           batch_normalization_620[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1163 (Conv2D)            (None, 32, 32, 25)   6300        activation_620[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_611 (Dropout)           (None, 32, 32, 25)   0           conv2d_1163[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_582 (Concatenate)   (None, 32, 32, 528)  0           concatenate_581[0][0]            \n",
            "                                                                 dropout_611[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_621 (BatchN (None, 32, 32, 528)  2112        concatenate_582[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_621 (Activation)     (None, 32, 32, 528)  0           batch_normalization_621[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1164 (Conv2D)            (None, 32, 32, 25)   13200       activation_621[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_612 (Dropout)           (None, 32, 32, 25)   0           conv2d_1164[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_39 (AveragePo (None, 16, 16, 25)   0           dropout_612[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1165 (Conv2D)            (None, 16, 16, 28)   700         average_pooling2d_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_622 (BatchN (None, 16, 16, 28)   112         conv2d_1165[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_622 (Activation)     (None, 16, 16, 28)   0           batch_normalization_622[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1166 (Conv2D)            (None, 16, 16, 25)   6300        activation_622[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_613 (Dropout)           (None, 16, 16, 25)   0           conv2d_1166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_583 (Concatenate)   (None, 16, 16, 50)   0           average_pooling2d_39[0][0]       \n",
            "                                                                 dropout_613[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1167 (Conv2D)            (None, 16, 16, 28)   1400        concatenate_583[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_623 (BatchN (None, 16, 16, 28)   112         conv2d_1167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_623 (Activation)     (None, 16, 16, 28)   0           batch_normalization_623[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1168 (Conv2D)            (None, 16, 16, 25)   6300        activation_623[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_614 (Dropout)           (None, 16, 16, 25)   0           conv2d_1168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_584 (Concatenate)   (None, 16, 16, 75)   0           concatenate_583[0][0]            \n",
            "                                                                 dropout_614[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1169 (Conv2D)            (None, 16, 16, 28)   2100        concatenate_584[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_624 (BatchN (None, 16, 16, 28)   112         conv2d_1169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_624 (Activation)     (None, 16, 16, 28)   0           batch_normalization_624[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1170 (Conv2D)            (None, 16, 16, 25)   6300        activation_624[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_615 (Dropout)           (None, 16, 16, 25)   0           conv2d_1170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_585 (Concatenate)   (None, 16, 16, 100)  0           concatenate_584[0][0]            \n",
            "                                                                 dropout_615[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1171 (Conv2D)            (None, 16, 16, 28)   2800        concatenate_585[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_625 (BatchN (None, 16, 16, 28)   112         conv2d_1171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_625 (Activation)     (None, 16, 16, 28)   0           batch_normalization_625[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1172 (Conv2D)            (None, 16, 16, 25)   6300        activation_625[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_616 (Dropout)           (None, 16, 16, 25)   0           conv2d_1172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_586 (Concatenate)   (None, 16, 16, 125)  0           concatenate_585[0][0]            \n",
            "                                                                 dropout_616[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1173 (Conv2D)            (None, 16, 16, 28)   3500        concatenate_586[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_626 (BatchN (None, 16, 16, 28)   112         conv2d_1173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_626 (Activation)     (None, 16, 16, 28)   0           batch_normalization_626[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1174 (Conv2D)            (None, 16, 16, 25)   6300        activation_626[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_617 (Dropout)           (None, 16, 16, 25)   0           conv2d_1174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_587 (Concatenate)   (None, 16, 16, 150)  0           concatenate_586[0][0]            \n",
            "                                                                 dropout_617[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1175 (Conv2D)            (None, 16, 16, 28)   4200        concatenate_587[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_627 (BatchN (None, 16, 16, 28)   112         conv2d_1175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_627 (Activation)     (None, 16, 16, 28)   0           batch_normalization_627[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1176 (Conv2D)            (None, 16, 16, 25)   6300        activation_627[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_618 (Dropout)           (None, 16, 16, 25)   0           conv2d_1176[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_588 (Concatenate)   (None, 16, 16, 175)  0           concatenate_587[0][0]            \n",
            "                                                                 dropout_618[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1177 (Conv2D)            (None, 16, 16, 28)   4900        concatenate_588[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_628 (BatchN (None, 16, 16, 28)   112         conv2d_1177[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_628 (Activation)     (None, 16, 16, 28)   0           batch_normalization_628[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1178 (Conv2D)            (None, 16, 16, 25)   6300        activation_628[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_619 (Dropout)           (None, 16, 16, 25)   0           conv2d_1178[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_589 (Concatenate)   (None, 16, 16, 200)  0           concatenate_588[0][0]            \n",
            "                                                                 dropout_619[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1179 (Conv2D)            (None, 16, 16, 28)   5600        concatenate_589[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_629 (BatchN (None, 16, 16, 28)   112         conv2d_1179[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_629 (Activation)     (None, 16, 16, 28)   0           batch_normalization_629[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1180 (Conv2D)            (None, 16, 16, 25)   6300        activation_629[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_620 (Dropout)           (None, 16, 16, 25)   0           conv2d_1180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_590 (Concatenate)   (None, 16, 16, 225)  0           concatenate_589[0][0]            \n",
            "                                                                 dropout_620[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1181 (Conv2D)            (None, 16, 16, 28)   6300        concatenate_590[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_630 (BatchN (None, 16, 16, 28)   112         conv2d_1181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_630 (Activation)     (None, 16, 16, 28)   0           batch_normalization_630[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1182 (Conv2D)            (None, 16, 16, 25)   6300        activation_630[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_621 (Dropout)           (None, 16, 16, 25)   0           conv2d_1182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_591 (Concatenate)   (None, 16, 16, 250)  0           concatenate_590[0][0]            \n",
            "                                                                 dropout_621[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1183 (Conv2D)            (None, 16, 16, 28)   7000        concatenate_591[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_631 (BatchN (None, 16, 16, 28)   112         conv2d_1183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_631 (Activation)     (None, 16, 16, 28)   0           batch_normalization_631[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1184 (Conv2D)            (None, 16, 16, 25)   6300        activation_631[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_622 (Dropout)           (None, 16, 16, 25)   0           conv2d_1184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_592 (Concatenate)   (None, 16, 16, 275)  0           concatenate_591[0][0]            \n",
            "                                                                 dropout_622[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1185 (Conv2D)            (None, 16, 16, 28)   7700        concatenate_592[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_632 (BatchN (None, 16, 16, 28)   112         conv2d_1185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_632 (Activation)     (None, 16, 16, 28)   0           batch_normalization_632[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1186 (Conv2D)            (None, 16, 16, 25)   6300        activation_632[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_623 (Dropout)           (None, 16, 16, 25)   0           conv2d_1186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_593 (Concatenate)   (None, 16, 16, 300)  0           concatenate_592[0][0]            \n",
            "                                                                 dropout_623[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1187 (Conv2D)            (None, 16, 16, 28)   8400        concatenate_593[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_633 (BatchN (None, 16, 16, 28)   112         conv2d_1187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_633 (Activation)     (None, 16, 16, 28)   0           batch_normalization_633[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1188 (Conv2D)            (None, 16, 16, 25)   6300        activation_633[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_624 (Dropout)           (None, 16, 16, 25)   0           conv2d_1188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_594 (Concatenate)   (None, 16, 16, 325)  0           concatenate_593[0][0]            \n",
            "                                                                 dropout_624[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1189 (Conv2D)            (None, 16, 16, 28)   9100        concatenate_594[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_634 (BatchN (None, 16, 16, 28)   112         conv2d_1189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_634 (Activation)     (None, 16, 16, 28)   0           batch_normalization_634[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1190 (Conv2D)            (None, 16, 16, 25)   6300        activation_634[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_625 (Dropout)           (None, 16, 16, 25)   0           conv2d_1190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_595 (Concatenate)   (None, 16, 16, 350)  0           concatenate_594[0][0]            \n",
            "                                                                 dropout_625[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1191 (Conv2D)            (None, 16, 16, 28)   9800        concatenate_595[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_635 (BatchN (None, 16, 16, 28)   112         conv2d_1191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_635 (Activation)     (None, 16, 16, 28)   0           batch_normalization_635[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1192 (Conv2D)            (None, 16, 16, 25)   6300        activation_635[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_626 (Dropout)           (None, 16, 16, 25)   0           conv2d_1192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_596 (Concatenate)   (None, 16, 16, 375)  0           concatenate_595[0][0]            \n",
            "                                                                 dropout_626[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1193 (Conv2D)            (None, 16, 16, 28)   10500       concatenate_596[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_636 (BatchN (None, 16, 16, 28)   112         conv2d_1193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_636 (Activation)     (None, 16, 16, 28)   0           batch_normalization_636[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1194 (Conv2D)            (None, 16, 16, 25)   6300        activation_636[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_627 (Dropout)           (None, 16, 16, 25)   0           conv2d_1194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_597 (Concatenate)   (None, 16, 16, 400)  0           concatenate_596[0][0]            \n",
            "                                                                 dropout_627[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1195 (Conv2D)            (None, 16, 16, 28)   11200       concatenate_597[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_637 (BatchN (None, 16, 16, 28)   112         conv2d_1195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_637 (Activation)     (None, 16, 16, 28)   0           batch_normalization_637[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1196 (Conv2D)            (None, 16, 16, 25)   6300        activation_637[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_628 (Dropout)           (None, 16, 16, 25)   0           conv2d_1196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_598 (Concatenate)   (None, 16, 16, 425)  0           concatenate_597[0][0]            \n",
            "                                                                 dropout_628[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1197 (Conv2D)            (None, 16, 16, 28)   11900       concatenate_598[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_638 (BatchN (None, 16, 16, 28)   112         conv2d_1197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_638 (Activation)     (None, 16, 16, 28)   0           batch_normalization_638[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1198 (Conv2D)            (None, 16, 16, 25)   6300        activation_638[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_629 (Dropout)           (None, 16, 16, 25)   0           conv2d_1198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_599 (Concatenate)   (None, 16, 16, 450)  0           concatenate_598[0][0]            \n",
            "                                                                 dropout_629[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1199 (Conv2D)            (None, 16, 16, 28)   12600       concatenate_599[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_639 (BatchN (None, 16, 16, 28)   112         conv2d_1199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_639 (Activation)     (None, 16, 16, 28)   0           batch_normalization_639[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1200 (Conv2D)            (None, 16, 16, 25)   6300        activation_639[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_630 (Dropout)           (None, 16, 16, 25)   0           conv2d_1200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_600 (Concatenate)   (None, 16, 16, 475)  0           concatenate_599[0][0]            \n",
            "                                                                 dropout_630[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1201 (Conv2D)            (None, 16, 16, 28)   13300       concatenate_600[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_640 (BatchN (None, 16, 16, 28)   112         conv2d_1201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_640 (Activation)     (None, 16, 16, 28)   0           batch_normalization_640[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1202 (Conv2D)            (None, 16, 16, 25)   6300        activation_640[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_631 (Dropout)           (None, 16, 16, 25)   0           conv2d_1202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_601 (Concatenate)   (None, 16, 16, 500)  0           concatenate_600[0][0]            \n",
            "                                                                 dropout_631[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1203 (Conv2D)            (None, 16, 16, 28)   14000       concatenate_601[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_641 (BatchN (None, 16, 16, 28)   112         conv2d_1203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_641 (Activation)     (None, 16, 16, 28)   0           batch_normalization_641[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1204 (Conv2D)            (None, 16, 16, 25)   6300        activation_641[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_632 (Dropout)           (None, 16, 16, 25)   0           conv2d_1204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_602 (Concatenate)   (None, 16, 16, 525)  0           concatenate_601[0][0]            \n",
            "                                                                 dropout_632[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_642 (BatchN (None, 16, 16, 525)  2100        concatenate_602[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_642 (Activation)     (None, 16, 16, 525)  0           batch_normalization_642[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1205 (Conv2D)            (None, 16, 16, 25)   13125       activation_642[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_633 (Dropout)           (None, 16, 16, 25)   0           conv2d_1205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_40 (AveragePo (None, 8, 8, 25)     0           dropout_633[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1206 (Conv2D)            (None, 8, 8, 28)     700         average_pooling2d_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_643 (BatchN (None, 8, 8, 28)     112         conv2d_1206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_643 (Activation)     (None, 8, 8, 28)     0           batch_normalization_643[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1207 (Conv2D)            (None, 8, 8, 25)     6300        activation_643[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_634 (Dropout)           (None, 8, 8, 25)     0           conv2d_1207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_603 (Concatenate)   (None, 8, 8, 50)     0           average_pooling2d_40[0][0]       \n",
            "                                                                 dropout_634[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1208 (Conv2D)            (None, 8, 8, 28)     1400        concatenate_603[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_644 (BatchN (None, 8, 8, 28)     112         conv2d_1208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_644 (Activation)     (None, 8, 8, 28)     0           batch_normalization_644[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1209 (Conv2D)            (None, 8, 8, 25)     6300        activation_644[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_635 (Dropout)           (None, 8, 8, 25)     0           conv2d_1209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_604 (Concatenate)   (None, 8, 8, 75)     0           concatenate_603[0][0]            \n",
            "                                                                 dropout_635[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1210 (Conv2D)            (None, 8, 8, 28)     2100        concatenate_604[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_645 (BatchN (None, 8, 8, 28)     112         conv2d_1210[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_645 (Activation)     (None, 8, 8, 28)     0           batch_normalization_645[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1211 (Conv2D)            (None, 8, 8, 25)     6300        activation_645[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_636 (Dropout)           (None, 8, 8, 25)     0           conv2d_1211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_605 (Concatenate)   (None, 8, 8, 100)    0           concatenate_604[0][0]            \n",
            "                                                                 dropout_636[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1212 (Conv2D)            (None, 8, 8, 28)     2800        concatenate_605[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_646 (BatchN (None, 8, 8, 28)     112         conv2d_1212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_646 (Activation)     (None, 8, 8, 28)     0           batch_normalization_646[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1213 (Conv2D)            (None, 8, 8, 25)     6300        activation_646[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_637 (Dropout)           (None, 8, 8, 25)     0           conv2d_1213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_606 (Concatenate)   (None, 8, 8, 125)    0           concatenate_605[0][0]            \n",
            "                                                                 dropout_637[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1214 (Conv2D)            (None, 8, 8, 28)     3500        concatenate_606[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_647 (BatchN (None, 8, 8, 28)     112         conv2d_1214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_647 (Activation)     (None, 8, 8, 28)     0           batch_normalization_647[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1215 (Conv2D)            (None, 8, 8, 25)     6300        activation_647[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_638 (Dropout)           (None, 8, 8, 25)     0           conv2d_1215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_607 (Concatenate)   (None, 8, 8, 150)    0           concatenate_606[0][0]            \n",
            "                                                                 dropout_638[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1216 (Conv2D)            (None, 8, 8, 28)     4200        concatenate_607[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_648 (BatchN (None, 8, 8, 28)     112         conv2d_1216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_648 (Activation)     (None, 8, 8, 28)     0           batch_normalization_648[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1217 (Conv2D)            (None, 8, 8, 25)     6300        activation_648[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_639 (Dropout)           (None, 8, 8, 25)     0           conv2d_1217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_608 (Concatenate)   (None, 8, 8, 175)    0           concatenate_607[0][0]            \n",
            "                                                                 dropout_639[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1218 (Conv2D)            (None, 8, 8, 28)     4900        concatenate_608[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_649 (BatchN (None, 8, 8, 28)     112         conv2d_1218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_649 (Activation)     (None, 8, 8, 28)     0           batch_normalization_649[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1219 (Conv2D)            (None, 8, 8, 25)     6300        activation_649[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_640 (Dropout)           (None, 8, 8, 25)     0           conv2d_1219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_609 (Concatenate)   (None, 8, 8, 200)    0           concatenate_608[0][0]            \n",
            "                                                                 dropout_640[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1220 (Conv2D)            (None, 8, 8, 28)     5600        concatenate_609[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_650 (BatchN (None, 8, 8, 28)     112         conv2d_1220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_650 (Activation)     (None, 8, 8, 28)     0           batch_normalization_650[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1221 (Conv2D)            (None, 8, 8, 25)     6300        activation_650[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_641 (Dropout)           (None, 8, 8, 25)     0           conv2d_1221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_610 (Concatenate)   (None, 8, 8, 225)    0           concatenate_609[0][0]            \n",
            "                                                                 dropout_641[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1222 (Conv2D)            (None, 8, 8, 28)     6300        concatenate_610[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_651 (BatchN (None, 8, 8, 28)     112         conv2d_1222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_651 (Activation)     (None, 8, 8, 28)     0           batch_normalization_651[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1223 (Conv2D)            (None, 8, 8, 25)     6300        activation_651[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_642 (Dropout)           (None, 8, 8, 25)     0           conv2d_1223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_611 (Concatenate)   (None, 8, 8, 250)    0           concatenate_610[0][0]            \n",
            "                                                                 dropout_642[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1224 (Conv2D)            (None, 8, 8, 28)     7000        concatenate_611[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_652 (BatchN (None, 8, 8, 28)     112         conv2d_1224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_652 (Activation)     (None, 8, 8, 28)     0           batch_normalization_652[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1225 (Conv2D)            (None, 8, 8, 25)     6300        activation_652[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_643 (Dropout)           (None, 8, 8, 25)     0           conv2d_1225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_612 (Concatenate)   (None, 8, 8, 275)    0           concatenate_611[0][0]            \n",
            "                                                                 dropout_643[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1226 (Conv2D)            (None, 8, 8, 28)     7700        concatenate_612[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_653 (BatchN (None, 8, 8, 28)     112         conv2d_1226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_653 (Activation)     (None, 8, 8, 28)     0           batch_normalization_653[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1227 (Conv2D)            (None, 8, 8, 25)     6300        activation_653[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_644 (Dropout)           (None, 8, 8, 25)     0           conv2d_1227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_613 (Concatenate)   (None, 8, 8, 300)    0           concatenate_612[0][0]            \n",
            "                                                                 dropout_644[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1228 (Conv2D)            (None, 8, 8, 28)     8400        concatenate_613[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_654 (BatchN (None, 8, 8, 28)     112         conv2d_1228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_654 (Activation)     (None, 8, 8, 28)     0           batch_normalization_654[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1229 (Conv2D)            (None, 8, 8, 25)     6300        activation_654[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_645 (Dropout)           (None, 8, 8, 25)     0           conv2d_1229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_614 (Concatenate)   (None, 8, 8, 325)    0           concatenate_613[0][0]            \n",
            "                                                                 dropout_645[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1230 (Conv2D)            (None, 8, 8, 28)     9100        concatenate_614[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_655 (BatchN (None, 8, 8, 28)     112         conv2d_1230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_655 (Activation)     (None, 8, 8, 28)     0           batch_normalization_655[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1231 (Conv2D)            (None, 8, 8, 25)     6300        activation_655[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_646 (Dropout)           (None, 8, 8, 25)     0           conv2d_1231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_615 (Concatenate)   (None, 8, 8, 350)    0           concatenate_614[0][0]            \n",
            "                                                                 dropout_646[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1232 (Conv2D)            (None, 8, 8, 28)     9800        concatenate_615[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_656 (BatchN (None, 8, 8, 28)     112         conv2d_1232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_656 (Activation)     (None, 8, 8, 28)     0           batch_normalization_656[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1233 (Conv2D)            (None, 8, 8, 25)     6300        activation_656[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_647 (Dropout)           (None, 8, 8, 25)     0           conv2d_1233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_616 (Concatenate)   (None, 8, 8, 375)    0           concatenate_615[0][0]            \n",
            "                                                                 dropout_647[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1234 (Conv2D)            (None, 8, 8, 28)     10500       concatenate_616[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_657 (BatchN (None, 8, 8, 28)     112         conv2d_1234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_657 (Activation)     (None, 8, 8, 28)     0           batch_normalization_657[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1235 (Conv2D)            (None, 8, 8, 25)     6300        activation_657[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_648 (Dropout)           (None, 8, 8, 25)     0           conv2d_1235[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_617 (Concatenate)   (None, 8, 8, 400)    0           concatenate_616[0][0]            \n",
            "                                                                 dropout_648[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1236 (Conv2D)            (None, 8, 8, 28)     11200       concatenate_617[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_658 (BatchN (None, 8, 8, 28)     112         conv2d_1236[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_658 (Activation)     (None, 8, 8, 28)     0           batch_normalization_658[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1237 (Conv2D)            (None, 8, 8, 25)     6300        activation_658[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_649 (Dropout)           (None, 8, 8, 25)     0           conv2d_1237[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_618 (Concatenate)   (None, 8, 8, 425)    0           concatenate_617[0][0]            \n",
            "                                                                 dropout_649[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1238 (Conv2D)            (None, 8, 8, 28)     11900       concatenate_618[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_659 (BatchN (None, 8, 8, 28)     112         conv2d_1238[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_659 (Activation)     (None, 8, 8, 28)     0           batch_normalization_659[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1239 (Conv2D)            (None, 8, 8, 25)     6300        activation_659[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_650 (Dropout)           (None, 8, 8, 25)     0           conv2d_1239[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_619 (Concatenate)   (None, 8, 8, 450)    0           concatenate_618[0][0]            \n",
            "                                                                 dropout_650[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1240 (Conv2D)            (None, 8, 8, 28)     12600       concatenate_619[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_660 (BatchN (None, 8, 8, 28)     112         conv2d_1240[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_660 (Activation)     (None, 8, 8, 28)     0           batch_normalization_660[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1241 (Conv2D)            (None, 8, 8, 25)     6300        activation_660[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_651 (Dropout)           (None, 8, 8, 25)     0           conv2d_1241[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_620 (Concatenate)   (None, 8, 8, 475)    0           concatenate_619[0][0]            \n",
            "                                                                 dropout_651[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1242 (Conv2D)            (None, 8, 8, 28)     13300       concatenate_620[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_661 (BatchN (None, 8, 8, 28)     112         conv2d_1242[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_661 (Activation)     (None, 8, 8, 28)     0           batch_normalization_661[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1243 (Conv2D)            (None, 8, 8, 25)     6300        activation_661[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_652 (Dropout)           (None, 8, 8, 25)     0           conv2d_1243[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_621 (Concatenate)   (None, 8, 8, 500)    0           concatenate_620[0][0]            \n",
            "                                                                 dropout_652[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1244 (Conv2D)            (None, 8, 8, 28)     14000       concatenate_621[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_662 (BatchN (None, 8, 8, 28)     112         conv2d_1244[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_662 (Activation)     (None, 8, 8, 28)     0           batch_normalization_662[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1245 (Conv2D)            (None, 8, 8, 25)     6300        activation_662[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_653 (Dropout)           (None, 8, 8, 25)     0           conv2d_1245[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_622 (Concatenate)   (None, 8, 8, 525)    0           concatenate_621[0][0]            \n",
            "                                                                 dropout_653[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_663 (BatchN (None, 8, 8, 525)    2100        concatenate_622[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_663 (Activation)     (None, 8, 8, 525)    0           batch_normalization_663[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1246 (Conv2D)            (None, 8, 8, 25)     13125       activation_663[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_654 (Dropout)           (None, 8, 8, 25)     0           conv2d_1246[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_41 (AveragePo (None, 4, 4, 25)     0           dropout_654[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_664 (BatchN (None, 4, 4, 25)     100         average_pooling2d_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_664 (Activation)     (None, 4, 4, 25)     0           batch_normalization_664[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_42 (AveragePo (None, 2, 2, 25)     0           activation_664[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_10 (Flatten)            (None, 100)          0           average_pooling2d_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 10)           1010        flatten_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 875,028\n",
            "Trainable params: 868,462\n",
            "Non-trainable params: 6,566\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ncSi8_i4JK0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ak - block 3 learning rate \n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.1\n",
        "    if epoch > 40:\n",
        "        lrate = 0.01\n",
        "    elif epoch > 75:\n",
        "        lrate = 0.001 \n",
        "    elif epoch > 100:\n",
        "        lrate = 0.0001   \n",
        "    return lrate\n",
        "\n",
        "# checkpointer\n",
        "# checkpointer = ModelCheckpoint(filepath='s1_v1_weights.{epoch:02d}-{val_loss:.2f}--{val_acc:.2f}.hdf5',monitor='val_acc', mode=max, verbose=1, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "lrate = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "#lr reducer\n",
        "# lr_reducer  = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "#                                    cooldown=0, patience=10, min_lr=0.1e-4)\n",
        "# early stopper\n",
        "\n",
        "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=20, verbose=1,mode='min')\n",
        "\n",
        "# gamma_regularizer=12(decay),beta_regularizer=12(decay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b4XOsW3ahSkL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# determine Loss function and Optimizer\n",
        "# decay=10e-4,momentum=0.9\n",
        "sgd = SGD(momentum=0.9,decay=10e-4)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ep1v_RxxdR-h",
        "colab": {},
        "outputId": "202221c4-1613-4ade-a433-3f44765c5ccd"
      },
      "cell_type": "code",
      "source": [
        "# ak - block 4 - image aug\n",
        "\n",
        "# we can compare the performance with or without data augmentation\n",
        "data_augmentation = True\n",
        "callbacks_list=[lrate,earlystopper]\n",
        "\n",
        "start = time.time()\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model_info = model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test, y_test),\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks_list\n",
        "        )\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by dataset std\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in 0 to 180 degrees\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally\n",
        "        height_shift_range=0.1,  # randomly shift images vertically\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.1,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    \n",
        "    model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=2*(x_train.shape[0]//batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        callbacks=callbacks_list\n",
        "                       )\n",
        "\n",
        "end = time.time()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/200\n",
            "1562/1562 [==============================] - 249s 159ms/step - loss: 1.4027 - acc: 0.4888 - val_loss: 2.0082 - val_acc: 0.4324\n",
            "Epoch 2/200\n",
            "1562/1562 [==============================] - 209s 134ms/step - loss: 1.0018 - acc: 0.6419 - val_loss: 1.3314 - val_acc: 0.5848\n",
            "Epoch 3/200\n",
            "1562/1562 [==============================] - 207s 132ms/step - loss: 0.8196 - acc: 0.7096 - val_loss: 0.9975 - val_acc: 0.6971\n",
            "Epoch 4/200\n",
            "1562/1562 [==============================] - 207s 132ms/step - loss: 0.7166 - acc: 0.7494 - val_loss: 0.9019 - val_acc: 0.7227\n",
            "Epoch 5/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.6446 - acc: 0.7759 - val_loss: 1.0085 - val_acc: 0.6987\n",
            "Epoch 6/200\n",
            "1562/1562 [==============================] - 205s 131ms/step - loss: 0.5909 - acc: 0.7953 - val_loss: 0.8343 - val_acc: 0.7413\n",
            "Epoch 7/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.5545 - acc: 0.8075 - val_loss: 0.6596 - val_acc: 0.8001\n",
            "Epoch 8/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.5201 - acc: 0.8203 - val_loss: 0.7531 - val_acc: 0.7712\n",
            "Epoch 9/200\n",
            "1562/1562 [==============================] - 204s 130ms/step - loss: 0.4889 - acc: 0.8313 - val_loss: 0.5755 - val_acc: 0.8247\n",
            "Epoch 10/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.4637 - acc: 0.8392 - val_loss: 0.5121 - val_acc: 0.8325\n",
            "Epoch 11/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.4460 - acc: 0.8457 - val_loss: 0.6285 - val_acc: 0.8150\n",
            "Epoch 12/200\n",
            "1562/1562 [==============================] - 204s 131ms/step - loss: 0.4266 - acc: 0.8520 - val_loss: 0.5968 - val_acc: 0.8167\n",
            "Epoch 13/200\n",
            "1562/1562 [==============================] - 207s 132ms/step - loss: 0.4091 - acc: 0.8591 - val_loss: 0.4912 - val_acc: 0.8480\n",
            "Epoch 14/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.3910 - acc: 0.8635 - val_loss: 0.5491 - val_acc: 0.8348\n",
            "Epoch 15/200\n",
            "1562/1562 [==============================] - 203s 130ms/step - loss: 0.3731 - acc: 0.8698 - val_loss: 0.4779 - val_acc: 0.8555\n",
            "Epoch 16/200\n",
            "1562/1562 [==============================] - 207s 133ms/step - loss: 0.3648 - acc: 0.8732 - val_loss: 0.4718 - val_acc: 0.8585\n",
            "Epoch 17/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.3537 - acc: 0.8771 - val_loss: 0.4950 - val_acc: 0.8482\n",
            "Epoch 18/200\n",
            "1562/1562 [==============================] - 204s 131ms/step - loss: 0.3425 - acc: 0.8797 - val_loss: 0.4845 - val_acc: 0.8530\n",
            "Epoch 19/200\n",
            "1562/1562 [==============================] - 207s 132ms/step - loss: 0.3305 - acc: 0.8851 - val_loss: 0.5389 - val_acc: 0.8417\n",
            "Epoch 20/200\n",
            "1562/1562 [==============================] - 234s 150ms/step - loss: 0.3222 - acc: 0.8887 - val_loss: 0.4053 - val_acc: 0.8777\n",
            "Epoch 21/200\n",
            "1562/1562 [==============================] - 236s 151ms/step - loss: 0.3128 - acc: 0.8918 - val_loss: 0.4342 - val_acc: 0.8698\n",
            "Epoch 22/200\n",
            "1562/1562 [==============================] - 222s 142ms/step - loss: 0.3065 - acc: 0.8929 - val_loss: 0.6266 - val_acc: 0.8238\n",
            "Epoch 23/200\n",
            "1562/1562 [==============================] - 214s 137ms/step - loss: 0.2961 - acc: 0.8964 - val_loss: 0.4990 - val_acc: 0.8593\n",
            "Epoch 24/200\n",
            "1562/1562 [==============================] - 211s 135ms/step - loss: 0.2884 - acc: 0.8997 - val_loss: 0.3651 - val_acc: 0.8862\n",
            "Epoch 25/200\n",
            "1562/1562 [==============================] - 211s 135ms/step - loss: 0.2832 - acc: 0.9003 - val_loss: 0.3194 - val_acc: 0.8975\n",
            "Epoch 26/200\n",
            "1562/1562 [==============================] - 210s 135ms/step - loss: 0.2752 - acc: 0.9030 - val_loss: 0.3734 - val_acc: 0.8899\n",
            "Epoch 27/200\n",
            "1562/1562 [==============================] - 209s 134ms/step - loss: 0.2725 - acc: 0.9047 - val_loss: 0.4006 - val_acc: 0.8823\n",
            "Epoch 28/200\n",
            "1562/1562 [==============================] - 208s 133ms/step - loss: 0.2631 - acc: 0.9081 - val_loss: 0.4001 - val_acc: 0.8816\n",
            "Epoch 29/200\n",
            "1562/1562 [==============================] - 210s 135ms/step - loss: 0.2546 - acc: 0.9115 - val_loss: 0.4093 - val_acc: 0.8757\n",
            "Epoch 30/200\n",
            "1562/1562 [==============================] - 208s 133ms/step - loss: 0.2510 - acc: 0.9124 - val_loss: 0.4297 - val_acc: 0.8749\n",
            "Epoch 31/200\n",
            "1562/1562 [==============================] - 209s 134ms/step - loss: 0.2464 - acc: 0.9139 - val_loss: 0.4335 - val_acc: 0.8720\n",
            "Epoch 32/200\n",
            "1562/1562 [==============================] - 208s 133ms/step - loss: 0.2415 - acc: 0.9150 - val_loss: 0.3728 - val_acc: 0.8901\n",
            "Epoch 33/200\n",
            "1562/1562 [==============================] - 207s 132ms/step - loss: 0.2327 - acc: 0.9182 - val_loss: 0.3416 - val_acc: 0.9018\n",
            "Epoch 34/200\n",
            "1562/1562 [==============================] - 205s 131ms/step - loss: 0.2317 - acc: 0.9180 - val_loss: 0.4213 - val_acc: 0.8826\n",
            "Epoch 35/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.2269 - acc: 0.9203 - val_loss: 0.3693 - val_acc: 0.8928\n",
            "Epoch 36/200\n",
            "1562/1562 [==============================] - 205s 131ms/step - loss: 0.2209 - acc: 0.9224 - val_loss: 0.3816 - val_acc: 0.8923\n",
            "Epoch 37/200\n",
            "1562/1562 [==============================] - 205s 131ms/step - loss: 0.2182 - acc: 0.9237 - val_loss: 0.3781 - val_acc: 0.8908\n",
            "Epoch 38/200\n",
            "1562/1562 [==============================] - 205s 131ms/step - loss: 0.2164 - acc: 0.9240 - val_loss: 0.4772 - val_acc: 0.8688\n",
            "Epoch 39/200\n",
            "1562/1562 [==============================] - 205s 131ms/step - loss: 0.2112 - acc: 0.9258 - val_loss: 0.4500 - val_acc: 0.8749\n",
            "Epoch 40/200\n",
            "1562/1562 [==============================] - 204s 131ms/step - loss: 0.2047 - acc: 0.9277 - val_loss: 0.3555 - val_acc: 0.8979\n",
            "Epoch 41/200\n",
            "1562/1562 [==============================] - 206s 132ms/step - loss: 0.2039 - acc: 0.9281 - val_loss: 0.5048 - val_acc: 0.8682\n",
            "Epoch 42/200\n",
            "1562/1562 [==============================] - 204s 131ms/step - loss: 0.1613 - acc: 0.9436 - val_loss: 0.3089 - val_acc: 0.9111\n",
            "Epoch 43/200\n",
            "1562/1562 [==============================] - 205s 131ms/step - loss: 0.1491 - acc: 0.9476 - val_loss: 0.2883 - val_acc: 0.9156\n",
            "Epoch 44/200\n",
            "1562/1562 [==============================] - 211s 135ms/step - loss: 0.1438 - acc: 0.9496 - val_loss: 0.2926 - val_acc: 0.9155\n",
            "Epoch 45/200\n",
            "1562/1562 [==============================] - 214s 137ms/step - loss: 0.1406 - acc: 0.9507 - val_loss: 0.2972 - val_acc: 0.9172\n",
            "Epoch 46/200\n",
            "1562/1562 [==============================] - 207s 133ms/step - loss: 0.1381 - acc: 0.9511 - val_loss: 0.3043 - val_acc: 0.9140\n",
            "Epoch 47/200\n",
            "1562/1562 [==============================] - 207s 132ms/step - loss: 0.1363 - acc: 0.9518 - val_loss: 0.2879 - val_acc: 0.9185\n",
            "Epoch 48/200\n",
            "1562/1562 [==============================] - 210s 135ms/step - loss: 0.1357 - acc: 0.9522 - val_loss: 0.2973 - val_acc: 0.9173\n",
            "Epoch 49/200\n",
            "1562/1562 [==============================] - 220s 141ms/step - loss: 0.1329 - acc: 0.9530 - val_loss: 0.2856 - val_acc: 0.9197\n",
            "Epoch 50/200\n",
            "1562/1562 [==============================] - 211s 135ms/step - loss: 0.1310 - acc: 0.9541 - val_loss: 0.3046 - val_acc: 0.9169\n",
            "Epoch 51/200\n",
            "1562/1562 [==============================] - 212s 136ms/step - loss: 0.1295 - acc: 0.9543 - val_loss: 0.3021 - val_acc: 0.9178\n",
            "Epoch 52/200\n",
            "1562/1562 [==============================] - 234s 150ms/step - loss: 0.1286 - acc: 0.9546 - val_loss: 0.3000 - val_acc: 0.9202\n",
            "Epoch 53/200\n",
            "1562/1562 [==============================] - 229s 147ms/step - loss: 0.1277 - acc: 0.9546 - val_loss: 0.3136 - val_acc: 0.9170\n",
            "Epoch 54/200\n",
            "1562/1562 [==============================] - 217s 139ms/step - loss: 0.1279 - acc: 0.9550 - val_loss: 0.3060 - val_acc: 0.9177\n",
            "Epoch 55/200\n",
            "1562/1562 [==============================] - 214s 137ms/step - loss: 0.1256 - acc: 0.9558 - val_loss: 0.3075 - val_acc: 0.9181\n",
            "Epoch 56/200\n",
            "1562/1562 [==============================] - 225s 144ms/step - loss: 0.1245 - acc: 0.9564 - val_loss: 0.3050 - val_acc: 0.9177\n",
            "Epoch 57/200\n",
            "1562/1562 [==============================] - 236s 151ms/step - loss: 0.1254 - acc: 0.9550 - val_loss: 0.3109 - val_acc: 0.9170\n",
            "Epoch 58/200\n",
            "1562/1562 [==============================] - 230s 147ms/step - loss: 0.1236 - acc: 0.9561 - val_loss: 0.3147 - val_acc: 0.9166\n",
            "Epoch 59/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 220s 141ms/step - loss: 0.1230 - acc: 0.9568 - val_loss: 0.3070 - val_acc: 0.9191\n",
            "Epoch 60/200\n",
            "1562/1562 [==============================] - 219s 140ms/step - loss: 0.1197 - acc: 0.9572 - val_loss: 0.3178 - val_acc: 0.9160\n",
            "Epoch 61/200\n",
            "1562/1562 [==============================] - 219s 140ms/step - loss: 0.1207 - acc: 0.9572 - val_loss: 0.3131 - val_acc: 0.9177\n",
            "Epoch 62/200\n",
            "1562/1562 [==============================] - 236s 151ms/step - loss: 0.1199 - acc: 0.9580 - val_loss: 0.3044 - val_acc: 0.9177\n",
            "Epoch 63/200\n",
            "1562/1562 [==============================] - 232s 148ms/step - loss: 0.1173 - acc: 0.9579 - val_loss: 0.3090 - val_acc: 0.9189\n",
            "Epoch 00063: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7jy0Tfy8JK0W",
        "colab_type": "code",
        "colab": {},
        "outputId": "1894dd24-74d7-489a-b0fe-24db55a2aa47"
      },
      "cell_type": "code",
      "source": [
        "print (\"Model took %0.2f hours to train\"%((end - start)/3600))\n",
        "\n",
        "plot_model_history(model_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model took 3.73 hours to train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZcWydmIVhZGr",
        "outputId": "4155982a-83c7-4775-f31f-bcbeaa22309b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 6s 586us/step\n",
            "Test loss: 0.30899357972368596\n",
            "Test accuracy: 0.9189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UE3lF6EH1r_L",
        "outputId": "56ded1ff-0d18-4299-dadd-cc9d7005acea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model_weights_s1_v1.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Og56VCRh5j8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}