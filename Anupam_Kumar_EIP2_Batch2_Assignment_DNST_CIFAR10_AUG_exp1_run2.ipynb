{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K70hAckqg0EA"
   },
   "outputs": [],
   "source": [
    "# https://keras.io/\n",
    "# !pip install -q keras \n",
    "# import keras \n",
    "# print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import time\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# batch_size = 32\n",
    "# num_classes =  10\n",
    "# epochs = 50\n",
    "# l = 40\n",
    "# num_filter = 10\n",
    "# compression = 0.5\n",
    "# dropout_rate = 0\n",
    "\n",
    "batch_size = 64\n",
    "num_classes =  10\n",
    "epochs = 100\n",
    "l = 20\n",
    "num_filter = 28\n",
    "compression = 0.9\n",
    "dropout_rate = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mB7o3zu1g6eT"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# convert to one hot encoding \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    " \n",
    "# #z-score\n",
    "# mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "# std = np.std(x_train,axis=(0,1,2,3))\n",
    "# x_train = (x_train-mean)/(std+1e-7)\n",
    "# x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, num_filter, dropout_rate):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        Dense_Conv2D_1_1 = Conv2D(num_filter, (1,1), use_bias=False ,padding='same')(temp)\n",
    "        BatchNorm = BatchNormalization()(Dense_Conv2D_1_1)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter, dropout_rate):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "# Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate=0.2)\n",
    "output = output_layer(Third_Transition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 22814
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "e25a0d0c-f142-4d4f-94d3-006930feaf26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 28)   756         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 28)   784         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 28)   112         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 28)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 25)   6300        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 25)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 53)   0           conv2d_1[0][0]                   \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 28)   1484        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 28)   112         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 28)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 25)   6300        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 25)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 78)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 28)   2184        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 28)   112         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 28)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 25)   6300        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 25)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 103)  0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 28)   2884        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 28)   112         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 28)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 25)   6300        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 25)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 128)  0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 28)   3584        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 28)   112         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 28)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 25)   6300        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 25)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 153)  0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 28)   4284        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 28)   112         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 28)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 25)   6300        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 25)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 178)  0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 28)   4984        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 28)   112         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 28)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 25)   6300        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 25)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 203)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 28)   5684        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 28)   112         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 28)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 25)   6300        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 25)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 228)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 28)   6384        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 28)   112         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 28)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 25)   6300        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 25)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 253)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 28)   7084        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 28)   112         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 28)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 25)   6300        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 25)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 278)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 28)   7784        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 28)   112         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 28)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 25)   6300        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 25)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 303)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 28)   8484        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 28)   112         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 28)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 25)   6300        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 25)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 328)  0           concatenate_11[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 28)   9184        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 28)   112         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 28)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 25)   6300        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 25)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 353)  0           concatenate_12[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 28)   9884        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 28)   112         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 28)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 25)   6300        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 25)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 378)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 28)   10584       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 28)   112         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 28)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 25)   6300        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 25)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 32, 32, 403)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 28)   11284       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 28)   112         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 28)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 25)   6300        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 25)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 428)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 28)   11984       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 28)   112         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 28)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 25)   6300        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 25)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 453)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 28)   12684       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 28)   112         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 28)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 25)   6300        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 25)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 32, 32, 478)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 28)   13384       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 28)   112         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 28)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 25)   6300        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 25)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 32, 32, 503)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 28)   14084       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 28)   112         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 28)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 25)   6300        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 32, 25)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 32, 32, 528)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 528)  2112        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 528)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 25)   13200       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 25)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 25)   0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 28)   700         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 28)   112         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 28)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 25)   6300        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 25)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 50)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 28)   1400        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 28)   112         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 28)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 25)   6300        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 25)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 75)   0           concatenate_21[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 28)   2100        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 28)   112         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 28)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 25)   6300        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 25)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 100)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 28)   2800        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 28)   112         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 28)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 25)   6300        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 25)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 125)  0           concatenate_23[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 28)   3500        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 28)   112         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 28)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 25)   6300        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 16, 16, 25)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 150)  0           concatenate_24[0][0]             \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 28)   4200        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 28)   112         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 28)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 25)   6300        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16, 16, 25)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 175)  0           concatenate_25[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 28)   4900        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 28)   112         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 28)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 25)   6300        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 16, 16, 25)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 200)  0           concatenate_26[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 28)   5600        concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 28)   112         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 28)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 25)   6300        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 16, 16, 25)   0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 225)  0           concatenate_27[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 28)   6300        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 28)   112         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 28)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 25)   6300        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 16, 16, 25)   0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 16, 16, 250)  0           concatenate_28[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 28)   7000        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 28)   112         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 28)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 25)   6300        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 16, 16, 25)   0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 16, 16, 275)  0           concatenate_29[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 28)   7700        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 28)   112         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 28)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 25)   6300        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 16, 16, 25)   0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 16, 16, 300)  0           concatenate_30[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 28)   8400        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 28)   112         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 28)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 25)   6300        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 16, 16, 25)   0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 16, 16, 325)  0           concatenate_31[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 28)   9100        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 28)   112         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 28)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 25)   6300        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 25)   0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 16, 16, 350)  0           concatenate_32[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 28)   9800        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 28)   112         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 28)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 25)   6300        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 25)   0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 16, 16, 375)  0           concatenate_33[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 28)   10500       concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 28)   112         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 28)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 25)   6300        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 25)   0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 16, 16, 400)  0           concatenate_34[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 28)   11200       concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 28)   112         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 28)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 25)   6300        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16, 16, 25)   0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 16, 16, 425)  0           concatenate_35[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 28)   11900       concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 28)   112         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 28)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 25)   6300        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16, 16, 25)   0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 16, 16, 450)  0           concatenate_36[0][0]             \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 28)   12600       concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 28)   112         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 28)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 25)   6300        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16, 16, 25)   0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 16, 16, 475)  0           concatenate_37[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 28)   13300       concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 28)   112         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 28)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 25)   6300        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 16, 16, 25)   0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 16, 16, 500)  0           concatenate_38[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 28)   14000       concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 28)   112         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 28)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 25)   6300        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 16, 16, 25)   0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 16, 16, 525)  0           concatenate_39[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 525)  2100        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 525)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 25)   13125       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 16, 16, 25)   0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 25)     0           dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 28)     700         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 28)     112         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 28)     0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 25)     6300        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 8, 8, 25)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 50)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 28)     1400        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 28)     112         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 28)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 25)     6300        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 8, 8, 25)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 75)     0           concatenate_41[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 28)     2100        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 28)     112         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 28)     0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 25)     6300        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 8, 8, 25)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 100)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 28)     2800        concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 28)     112         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 28)     0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 25)     6300        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 8, 8, 25)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 125)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 28)     3500        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 28)     112         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 28)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 25)     6300        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 8, 8, 25)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 8, 8, 150)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 28)     4200        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 28)     112         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 28)     0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 25)     6300        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 8, 8, 25)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 8, 8, 175)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 28)     4900        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 28)     112         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 28)     0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 25)     6300        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 8, 8, 25)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 8, 8, 200)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 28)     5600        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 28)     112         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 28)     0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 25)     6300        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 8, 8, 25)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 8, 8, 225)    0           concatenate_47[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 28)     6300        concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 28)     112         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 28)     0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 25)     6300        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 8, 8, 25)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 8, 8, 250)    0           concatenate_48[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 28)     7000        concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 28)     112         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 28)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 25)     6300        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 8, 8, 25)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 8, 8, 275)    0           concatenate_49[0][0]             \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 28)     7700        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 28)     112         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 28)     0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 25)     6300        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 8, 8, 25)     0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 8, 8, 300)    0           concatenate_50[0][0]             \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 28)     8400        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 28)     112         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 28)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 25)     6300        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 8, 8, 25)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 8, 8, 325)    0           concatenate_51[0][0]             \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 8, 8, 28)     9100        concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 28)     112         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 28)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 8, 8, 25)     6300        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 8, 8, 25)     0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 8, 8, 350)    0           concatenate_52[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 8, 8, 28)     9800        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 28)     112         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 28)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 8, 8, 25)     6300        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 8, 8, 25)     0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 8, 8, 375)    0           concatenate_53[0][0]             \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 8, 8, 28)     10500       concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 28)     112         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 28)     0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 8, 25)     6300        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 8, 8, 25)     0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 8, 8, 400)    0           concatenate_54[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 28)     11200       concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 28)     112         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 28)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 25)     6300        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 8, 8, 25)     0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 8, 8, 425)    0           concatenate_55[0][0]             \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 8, 8, 28)     11900       concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 28)     112         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 28)     0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 8, 8, 25)     6300        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 8, 8, 25)     0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 8, 8, 450)    0           concatenate_56[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 8, 8, 28)     12600       concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 28)     112         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 28)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 25)     6300        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 8, 8, 25)     0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 8, 8, 475)    0           concatenate_57[0][0]             \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 8, 8, 28)     13300       concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 28)     112         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 28)     0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 8, 8, 25)     6300        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 8, 8, 25)     0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 8, 8, 500)    0           concatenate_58[0][0]             \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 8, 8, 28)     14000       concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 28)     112         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 28)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 8, 8, 25)     6300        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 8, 8, 25)     0           conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 8, 8, 525)    0           concatenate_59[0][0]             \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 525)    2100        concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 525)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 8, 8, 25)     13125       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 8, 8, 25)     0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 4, 25)     0           dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 4, 4, 25)     100         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 4, 4, 25)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 2, 2, 25)     0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1010        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 875,028\n",
      "Trainable params: 868,462\n",
      "Non-trainable params: 6,566\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.load_weights('DNST_model_weights_s1_v1.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ak - block 3 learning rate \n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.01\n",
    "    if epoch > 20:\n",
    "        lrate = 0.001\n",
    "    elif epoch > 50:\n",
    "        lrate = 0.0001 \n",
    "    return lrate\n",
    "\n",
    "# checkpointer\n",
    "# checkpointer = ModelCheckpoint(filepath='s1_v1_weights.{epoch:02d}-{val_loss:.2f}--{val_acc:.2f}.hdf5',monitor='val_acc', mode=max, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "lrate = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "#lr reducer\n",
    "# lr_reducer  = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "#                                    cooldown=0, patience=10, min_lr=0.1e-4)\n",
    "# early stopper\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=30, verbose=1,mode='min')\n",
    "\n",
    "# gamma_regularizer=12(decay),beta_regularizer=12(decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "# decay=10e-4,momentum=0.9\n",
    "sgd = SGD(momentum=0.9,decay=10e-4)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ep1v_RxxdR-h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 112s 2ms/step - loss: 0.0674 - acc: 0.9767 - val_loss: 0.2384 - val_acc: 0.9335\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 95s 2ms/step - loss: 0.0621 - acc: 0.9787 - val_loss: 0.2408 - val_acc: 0.9328\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0591 - acc: 0.9795 - val_loss: 0.2396 - val_acc: 0.9323\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0579 - acc: 0.9804 - val_loss: 0.2392 - val_acc: 0.9322\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 0.0561 - acc: 0.9805 - val_loss: 0.2416 - val_acc: 0.9315\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0554 - acc: 0.9809 - val_loss: 0.2431 - val_acc: 0.9320\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0539 - acc: 0.9818 - val_loss: 0.2446 - val_acc: 0.9320\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0521 - acc: 0.9823 - val_loss: 0.2464 - val_acc: 0.9329\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0520 - acc: 0.9822 - val_loss: 0.2451 - val_acc: 0.9334\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0504 - acc: 0.9829 - val_loss: 0.2486 - val_acc: 0.9324\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0502 - acc: 0.9833 - val_loss: 0.2468 - val_acc: 0.9321\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.0489 - acc: 0.9843 - val_loss: 0.2442 - val_acc: 0.9327\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0462 - acc: 0.9842 - val_loss: 0.2546 - val_acc: 0.9311\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0476 - acc: 0.9837 - val_loss: 0.2560 - val_acc: 0.9309\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0455 - acc: 0.9844 - val_loss: 0.2534 - val_acc: 0.9321\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0454 - acc: 0.9846 - val_loss: 0.2551 - val_acc: 0.9320\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0454 - acc: 0.9852 - val_loss: 0.2617 - val_acc: 0.9309\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0435 - acc: 0.9855 - val_loss: 0.2557 - val_acc: 0.9326\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0418 - acc: 0.9863 - val_loss: 0.2613 - val_acc: 0.9309\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0419 - acc: 0.9859 - val_loss: 0.2594 - val_acc: 0.9308\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0430 - acc: 0.9852 - val_loss: 0.2639 - val_acc: 0.9307\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0396 - acc: 0.9871 - val_loss: 0.2619 - val_acc: 0.9321\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0402 - acc: 0.9867 - val_loss: 0.2629 - val_acc: 0.9317\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.0386 - acc: 0.9868 - val_loss: 0.2629 - val_acc: 0.9319\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0384 - acc: 0.9870 - val_loss: 0.2613 - val_acc: 0.9320\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.0399 - acc: 0.9868 - val_loss: 0.2634 - val_acc: 0.9319\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0386 - acc: 0.9872 - val_loss: 0.2617 - val_acc: 0.9318\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 89s 2ms/step - loss: 0.0381 - acc: 0.9878 - val_loss: 0.2623 - val_acc: 0.9319\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.0392 - acc: 0.9871 - val_loss: 0.2629 - val_acc: 0.9321\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0388 - acc: 0.9874 - val_loss: 0.2625 - val_acc: 0.9322\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 90s 2ms/step - loss: 0.0385 - acc: 0.9868 - val_loss: 0.2619 - val_acc: 0.9320\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "# ak - block 4 - image aug\n",
    "\n",
    "# we can compare the performance with or without data augmentation\n",
    "data_augmentation = False\n",
    "callbacks_list=[lrate,earlystopper]\n",
    "\n",
    "start = time.time()\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model_info = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks_list\n",
    "        )\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by dataset std\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in 0 to 180 degrees\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.1,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    \n",
    "    model_info = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=2*(x_train.shape[0]//batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list\n",
    "                       )\n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model took 0.79 hours to train\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAFNCAYAAABVKNEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xl8XXWd//HXJ0uzNWnWNqVJk3TfaSEtRRAQRQrILhQVl9EBZ0YFZJgRR0cdRGXU328ct1Fw6oijMBVcGH/FAtpSENAGodB9b5OuWZo0aZJm+/z+OCfNbZq2Cc1Nmtz38/E4j3vWez+3D+jp+57vYu6OiIiIiIiIxI64wS5AREREREREBpaCoIiIiIiISIxREBQREREREYkxCoIiIiIiIiIxRkFQREREREQkxigIioiIiIiIxBgFQZEoMbNiM3MzS+jFuR8xsxcHoi4REZGhSvdWkf6jICgCmNlOM2sxs9xu+18LbzjFg1PZcbWMNLMGM3t6sGsRERE5nbP53tqXQCkyXCkIinTZAbyvc8PMZgOpg1fOCW4GjgJXmFn+QH6wbpQiIvIWne33VpGYpSAo0uWnwIcitj8MPBp5gpmNMrNHzazSzHaZ2efNLC48Fm9m3zSzKjPbDlzTw7X/aWb7zGyPmT1oZvF9qO/DwA+AN4Dbu713oZn9Mqyr2sy+G3HsDjPbYGb1ZrbezM4L97uZTYo477/M7MFw/TIzqzCzz5jZfuDHZpZlZr8NP+NQuF4QcX22mf3YzPaGx38d7l9rZtdGnJcY/hnN68N3FxGRoelsv7eewMySzOxb4f1sb7ieFB7LDe9/tWZWY2YvRNT6mbCGejPbZGbvPJM6RKJNQVCkyytAhplND28itwH/3e2c7wCjgAnApQQ3t78Kj90BvAeYB5QC7+127X8BbcCk8Jx3A3/dm8LMrAi4DPhZuHwo4lg88FtgF1AMjAMeD4/dAnwpPD8DuA6o7s1nAvlANlAE3Enw98WPw+3xQBPw3Yjzf0rwK+9MYDTwb+H+Rzk+uF4N7HP313pZh4iIDF1n7b31FD4HLATmAucCC4DPh8f+HqgA8oAxwD8BbmZTgU8C8909HbgS2HmGdYhElYKgyPE6f7m8AtgA7Ok8EHED+6y717v7TuD/AB8MT7kV+Ja7l7t7DfC1iGvHEASge9z9iLsfJAhKt/Wyrg8Cb7j7eoKQNzPiidoC4BzgH8L3bnb3zs7xfw183d1Xe2Cru+/q5Wd2AF9096Pu3uTu1e7+pLs3uns98BWCGzZmNha4Cvgbdz/k7q3u/nz4Pv8NXG1mGRHf5ae9rEFERIa+s/XeejIfAB5w94PuXgn8S0Q9rcBYoCi8173g7g60A0nADDNLdPed7r7tDOsQiSr1+xE53k+BVUAJ3ZquALlAIsGTt067CJ7AQRDGyrsd61QUXrvPzDr3xXU7/1Q+BDwC4O57zOx5guY1rwGFwC53b+vhukLgrd6IKt29uXPDzFIJbrCLgKxwd3p4Ey8Eatz9UPc3cfe9ZvZH4GYz+xVBYLz7LdYkIiJDz9l6bz2Zc3qo55xw/RsELW2eCT/zYXd/yN23mtk94bGZZrYcuNfd955hLSJRoyeCIhHCp2U7CH5h/GW3w1UEvwQWRewbT9cvm/sIAlHksU7lBAO95Lp7ZrhkuPvM09VkZm8DJgOfNbP9YZ+9C4D3h4O4lAPjTzKgSzkw8SRv3cjxHfa7D0Dj3bb/HpgKXODuGcAlnSWGn5NtZpkn+ayfEDQPvQV42d33nOQ8EREZZs7Ge+tp7O2hnr3hd6l397939wkE3S3u7ewL6O4/d/eLw2sd+NczrEMkqhQERU70MeBydz8SudPd24GlwFfMLD3st3cvXX0dlgJ3mVmBmWUB90dcuw94Bvg/ZpZhZnFmNtHMLu1FPR8GngVmEPRXmAvMAlIInq79meBG+ZCZpZlZspldFF77I+A+MzvfApPCugFeJwiT8Wa2iLCZ5ymkE/QLrDWzbOCL3b7f08D3w0FlEs3skohrfw2cR/AksPuvwSIiMvydbffWTknhfbNziQMeAz5vZnkWTH3xhc56zOw94b3UgDqCJqEdZjbVzC4PB5VpJrhfdvTxz0hkQCkIinTj7tvcvewkhz8FHAG2Ay8CPweWhMceAZYDa4C/cOKvnh8CRgDrgUPAEwT9DE7KzJIJ+kd8x933Ryw7CJrafDi8iV5L0FF+N0En9sXhd/kFQV++nwP1BIEsO3z7u8Pragn6Q/z6VLUA3yIIn1UEnf9/1+34Bwl+1d0IHATu6Tzg7k3AkwTNgrr/uYiIyDB3Nt1bu2kgCG2dy+XAg0AZwSjdb4af+2B4/mTgufC6l4Hvu/sKgv6BDxHcI/cTDJr22T7UITLgLOjfKiISXWb2BWCKu99+2pNFREREJKo0WIyIRF3YlPRjdI26JiIiIiKDSE1DRSSqzOwOgg79T7v7qsGuR0RERETUNFRERERERCTm6ImgiIiIiIhIjIlqEDSzRWa2ycy2mtn9PRwvMrPfm9kbZrbSzAoijv2rma0Nl8XRrFNERERERCSWRK1pqJnFA5uBKwiGs18NvM/d10ec8wvgt+7+EzO7HPgrd/+gmV1DMPT8VQTD8a4E3unuh0/2ebm5uV5cXByV7yIiImeXV199tcrd8wa7jqFC90gRkdjQl/tjNEcNXQBsdfftAGb2OHA9wTwvnWYQTBoKsIKuecxmAKvcvQ1oM7M3gEUEk4r2qLi4mLKyk01PIyIiw4mZ7RrsGoYS3SNFRGJDX+6P0WwaOo5gpMBOFeG+SGuAm8L1G4F0M8sJ9y8ys1QzywXeARRGsVYREREREZGYMdiDxdwHXGpmrwGXAnuAdnd/BlgGvAQ8BrwMtHe/2MzuNLMyMyurrKwcwLJFRERERESGrmgGwT0c/xSvINx3jLvvdfeb3H0e8LlwX234+hV3n+vuVwBG0N+Qbtc/7O6l7l6al6euIiIiIiIiIr0RzT6Cq4HJZlZCEABvA94feULY7LPG3TuAzwJLwv3xQKa7V5vZHGAO8ExfC2htbaWiooLm5uYz+yZDQHJyMgUFBSQmJg52KSIiIiIicpaLWhB09zYz+ySwHIgHlrj7OjN7AChz96eAy4CvmZkDq4BPhJcnAi+YGcBh4PZw4Jg+qaioID09neLiYsL3GpbcnerqaioqKigpKRnsckRERERE5CwXzSeCuPsygr5+kfu+ELH+BPBED9c1E4wcekaam5uHfQgEMDNycnJQP0kREREREemNwR4sJuqGewjsFCvfU0REREREztywD4KDrba2lu9///t9vu7qq6+mtrY2ChWJiIiIiEisUxCMspMFwba2U3d5XLZsGZmZmdEqS0REREREYlhU+wgK3H///Wzbto25c+eSmJhIcnIyWVlZbNy4kc2bN3PDDTdQXl5Oc3Mzd999N3feeScAxcXFlJWV0dDQwFVXXcXFF1/MSy+9xLhx4/jNb35DSkrKIH8zERkKDtY380Z5HWYwvySbjGSNLCwiMix0tMP2FdDRAWPnQHr+YFckQ4yCYJQ99NBDrF27ltdff52VK1dyzTXXsHbt2mOjey5ZsoTs7GyampqYP38+N998Mzk5Oce9x5YtW3jsscd45JFHuPXWW3nyySe5/fbbB+PriMhZrL65lTf31LGmvI43KmpZU17L3rqu6XPiDGaPG8XCiTm8bWIu84uzSB2h24CIyJDSdAj+8lNY/QjU7u7aP3IM5M+BsecGwXDsuZBZBH0dR6K9DRqroOEAtDaBO+DgHRHr4faxdYe4eMgqCj4zLv7Mv+Pe12Hf67D3NajaCqMKIG8q5E2D0dMgdyokjTyzz+mNtqNwtAGOHoaWBuhog4TkYElMgYQkSAhfh9iYHTHzL4B/+d91rN97uF/fc8Y5GXzx2pl9umbBggXHTfHw7W9/m1/96lcAlJeXs2XLlhOCYElJCXPnzgXg/PPPZ+fOnWdWuIgMeS1tHWzcf5g15bWsqahjTXktWysbgns0UJSTyvnF2Xy0YBRzCzNpbXde3l7Ny9uqWPLiDn74/HYS4oxzCzN528QcLpyQw3lFWSQn9nzz7uhwahpb2F/XzIHDzew/3MyBw0c5UNdMYoJxbkEm88ZnMSE3jbi4oXUjFBEZEg6shz//EN5YCq2NUHQxvPtBSMuDfWtg3xvB67Y/gLcH1ySPigiH50LORGiqhSOVQdBrOBgsRw52rTdWA/7W64xPguwJkDsJciZD7uTwdRKkZJ14fnNdUPfeMPTtfQ0O7eg6nlUchL7De4InoO0tXcdGFXaFw2PLFEjKCP6MjtZD8+Hg9WhdxPbhE9dbGsLAVw8t9V3rHa29/+49BcSkkTBiJCSlB3UlpQf7ktKDZUR613ryKMif9Zb/6PsqZoLg2SItLe3Y+sqVK3nuued4+eWXSU1N5bLLLqO5ufmEa5KSko6tx8fH09TUNCC1igw17s6KTQepbmihKCeN8dmpjE5PGvBg4u4caWmnqaWd9OSEk4ar02nvcPbWNrGz+gg7qxvZWXUkWKqPsLumkdb24EadkzaCcwszec+cczi3cBRzCjLJThtxwvtdODEHrphCY0sbZTsP8fL2al7aVs33VmzlO3/YyoiEOM4bn8n5RVk0tXQcC3z765o5WN987PM6mUHuyCSaW9r571eCX6UzkhOYOz6LuYWZzBufybzCTDJTT6xFROSssfX38PzXg6dMl/0TpI/pv/dub4V1vw6eIo2ZEQSaxOTeX9/RDpueDgLgjlVByJh9C1zwccif3XVe0du61lub4OD6MByGAfHPj0D70RPfPyEFRo4OlqwSKLygazttNIxIC59yGVjcqdfbW6BmO1RtgeqtcHBjUHtHxLgYqblhMJwEbc1B6Kve2nV81Hg4Zy6c9yE4Z14QXlOzI/4826B2F1RuhIMboHJTsL7zxeD9Oll8Vxg+lcS0rhDWGdBSi48PayMiQ9tIiEsIPqtzaW2GtqbwtXNfU/AksbURWo4EgbJ+XxhIw6eLPYXttDz4h60n7o+SmAmCfX1y11/S09Opr6/v8VhdXR1ZWVmkpqayceNGXnnllQGuTmT4qG1s4Z9+9SbL3tx/3P6khDjGZ6cGS04qReHr+Ow0CrNTSEoIQpq7c7StgyNH22hsaQ+XE9cbmts43NxKfXMbh5taOdzcRn1z12t9+NoR8ff7iIQ4RqUkkpmSyKjIJfX47SMt7ceFvfKaJlraO469T3JiHMU5aUwaPZIrZuQze9wo5hSMoiArpU9TyKSOSOCSKXlcMiUPCJqUrt5Zw0tbq3l5ezXfX7mN5IR4xo5KZkxGMgtKshmTkUx+RhL54b78UcnkjUwiIT6Ojg5ne1UDf9ldy2u7a3lt9yG++4ctx/4MSnLTmNcZDMdnMTU/ncR4jVUmIoOs/gAs/yysfRIyxsGeMnjzCXj7vbDw74KnOm9VR3vwviu+Aod2du23OMieGITC0TNh9HQYMzN46hXZnLKxBl77Kaz+UdD8M6MA3vUlOO/DxwejniSmwLjzg6VTeytUbYaaHZCa0xX2Rozs3+aMxRcfv93eCod2QfWWMCBuCZp5bv4dxI8Iwt65t4Whbx6k5fT8vp3iE4KnmjkTYdo1Xfs72sOAuCkIiC0NXU/fkkcd/zQuOaPrSVz8IEUh9yAgtoRPHY8eDgJix6kHk+xvMRMEB0tOTg4XXXQRs2bNIiUlhTFjun5lWrRoET/4wQ+YPn06U6dOZeHChYNYqcjQ9eKWKv7+F69Tc6SFzyyaxqJZ+eyuaWR39RF2VTcG6zWNvLy9msaWrl8IzSArdQQtbR00trQdF95OJc5gZFICGSmJpCcnkp6cwLjMFDKS00lP7tyfQEpiPPVH26hrbKWuqWvZV9fMxv31HG5qpf7o8X/pR4a9d80YQ3FOGsU5aZTkpkXt6WZ6ciKXTxvD5dOCv59a2jpIjLdeh8u4OGPS6HQmjU7n1tJCAI4cbeONijpeKz/Ea7trWbWlil++tgeAr944m/dfML7fv4eISK90tEPZEvj9l4MnOZfeDxd/Guoq4NkvwO8fgLIfB8Fr1s19C0ruwVOwP3w5eCo3Zja8f2kQ9A6sC0LKwfXBU7r1T3HsqVBCStDEccxMwIIQ2dYUNv/8Cky9+sxCS3xi8N5jBvjBSHxi0CQ0dxJMvSp6nxMXHzRHzZ4Q3c/pL2bhE8eRgzrIj7mfQRvgs0hpaamXlZUdt2/Dhg1Mnz59kCoaeLH2fUWaW9v55vJN/OjFHUzMS+Pfb5vHrHGjTnq+u1PV0MLumqBp5a7qRg7WHyUlMZ7UEfGkjkgIX8P1pHhSE+NJS0o4tm9kcgJpI+L79ATuVNraOzjc3EZdUyvJiXGMSU8eln3s3J2KQ028Xl7L+UVZnJN5ZiMfm9mr7l7aT+UNez3dI0Vi0r434Lf3wJ5XoeQSuOb/Bk0VI21/Hp75HOx/Ewrmw5VfhcIFp3/vHauCEFmxOnjqd/nnYMaNEHeSFhAtR7qaOB5YDwfDoNhcB3NuhQUfH9D+YjI89OX+qCeCIvKWtLR1ULarhlWbq1i1uZKd1UcYOyqZwuxUCrNSKcxOoSCra31USmK/hSeATfvrufvx19i4v54PLizin66eTsqIU/fFMzPy0pPIS0/i/KLTNK0ZIAnxcWSnjeixT99wYmbBfxvZqYNdiojEoqMNsOKr8Kf/gJRsuPHhIGz1dF+acCnc+TyseSx4avifV8DMm4InhFlFJ56/59UgAG5fGTQxvfbbMPf9wdOwUxmRdmITTgimgzhZeBTpRwqCItJrO6uOsGpLJas2V/LytmqOtLSTEGecV5TFraWF7K9rpvxQI3/ZdYjDzcc3eUxPSmBcVsqxoHhu4SgunpRLzsikk3xazzo6nP96aScP/W4jGckJLPlI6bEmjSIiIifY8Ft4+h+DUSfP/0gQ6HoavTJSXDzMux1m3AAvfRv++G3Y+P/gwr+Di+8N+pkd3Bg0Ad3426Df3ZVfhdKP9W0wmB4/WyFQBoaCoIicVMPRNl7eVs3zmw+yanMVu2saASjMTuGGeeO4dEoeF07MIb2HScrrmlqpONRIeU0TFYcaqTjURHlNI7urG3lxSxVL/tiOhfPaXTI5GLhk3vjMUw4icuBwM/f9Yg0vbKni8mmj+fp755DbxyApIiKDwB2OVAUDehzaGb7uCuaiG78wGPUyq6R/By6p3Q1PfwY2LQsGZnnvj2H8BX17j6SR8I5/Ckax/P2X4cV/C+bwK7owCIaJacFIowv/NgiHIkOIgqCI0HC0jV3VR9hZ1RhMVVB1hG2VDbxRUUdbh5M6Ip4LJ+TwsYtLuGRKHsU5qadt5hmMhDmKmeec2GevvcN5c08dqzYHTxf/4/ltfHfFVtKTErhwYg6XTs3jksl5xzUj/N3a/Xz2l2/Q1NrOgzfM4gMXjO/XpqYiItIParYH/d06g96x193QeuT4c1NzgyH+X/tpsJ0+FsZfGITCoouCOeF6+3Ss7WgwDUHlpmB0zMqNsHl5cOyKB4JRQE/XVPNURhXATT8Mpm1Y/jnY8ixc+Am46NOnH+lS5CylICgSI5pb29lW2XBc2Oucn66y/vi5hfLSkyjJSeNjby/h0sl5nF+cdWyahf4QH2fMLcxkbmEmd71zMnVNrby0tSpsdlrFM+sPADAhN41LpuRR39zGk3+pYNa4DL61eB6TRo/st1pERKSf/OWn8NSnODYS5oj0oE9d9gSY+A7ILAq2M4sgc3zwtK2jIwhuu/4Iu14KlnW/DK5PyYoIhm+D/HODOdqqNneFvcrw9dDOiHnjLPicae+Bd/5z8Fn9Zdx58NGngyec+jFShjgFQZFhqKWtg03763ljTy1vVtTxRkUdmw/U0xYxP8Lo9CSKc9J4x9Q8isLpCYpyUinOSSMtaWD/ahiVkshVs8dy1eyxuDvbKo+wanMlz2+u5PHVuzna1sHfXTaRe941hREJ6jshInLWefUn8L93wcTL4fJ/DqZLSMk6fViKiwsmch89DeZ/LAhYtbvCUBiGw03LgnMTko+fNDwuIZyTbybMuil4gpg7JRgF9EzmAOwNhUAZBhQEzzIjR46koaFhsMuQIaS1vYPNB+qDwLenjrV76ti4r/7YROSZqYnMHjeKj0+bwIyxo44FvoEOe71lZkwaPZJJo0fy0YtLaG5tp765jbx09QWU4cPMFgH/DsQDP3L3h7odvxf4a6ANqAQ+6u67wmPtwJvhqbvd/boBK1ykJ2U/DqZkmHQFLP7vMxssxSwIkVnFwcibAIf3we6XoOLVIFzmTQlCX/aEM2vuKRLjzs5/CYoI7s7hpjYqG45S1XCUyvrgtarhKFX1LVQ1HOVAfTObDzTQ0haEvvTkBGaPG8VfXVzMnHGZzCkYRUFWypDuS5ecGE9yYv81SxUZbGYWD3wPuAKoAFab2VPuvj7itNeAUndvNLO/Bb4OLA6PNbn73AEtWuRkVv8n/L97YfKVsPinkBCFH+0yxgYTu8+6uf/fWySGKQhG2f33309hYSGf+MQnAPjSl75EQkICK1as4NChQ7S2tvLggw9y/fXXD3Klsau64SgrNlXS3tFBUkI8SQlxjEiIIykhPnyNIykxjhHxcSQlBsczkhP7tYlidcNR/ritmhe3VLJxfz2V9Uepbmg59lQvUnyckZ02gtyRwXx4H1qYw+yCUcwpyKQoO3VYTkYuMswsALa6+3YAM3scuB44FgTdfUXE+a8Atw9ohSK98edHYNl9MGUR3PpodEKgiESNgmCULV68mHvuuedYEFy6dCnLly/nrrvuIiMjg6qqKhYuXMh11103pJ/aDDUdHc6LW6v4n9XlPLN+P63tfvqLIiTGGzPGZnBuYSbnFmRybmEmE3LTeh3CmlvbeXXXIV7YUsULWypZt/cwABnJCcwdn8WUMenkjkwid+QI8tKTwvVgOyt1hMKeyNA2DiiP2K4ATjWm/ceApyO2k82sjKDZ6EPu/uv+L1HkNP70w2BuvqlXwy3/pRAoMgTFThB8+n7Y/+bpz+uL/Nlw1UOnPGXevHkcPHiQvXv3UllZSVZWFvn5+Xz6059m1apVxMXFsWfPHg4cOEB+fn7/1icn2FvbxC/KKlhaVs6e2iayUhP54MJibjpvHFlpIzja2k5LewdHWzs42tZBS1sHR9vaT1jfc6iJNRW1PPlqBY++vAsIJkyfUzjqWDCcW5jJmIygn4S7s3F/PS9uqeKFrVX8eUc1za0dJMYb88Zncd+7p3Dx5DxmjxtFvEKeiITM7HagFLg0YneRu+8xswnAH8zsTXff1sO1dwJ3Aowf34+jJsrZpWoLrP8NNNZA3lQYPT14TT5x6p5+88p/wO/uD0blfO+PIWFE9D5LRKImdoLgILrlllt44okn2L9/P4sXL+ZnP/sZlZWVvPrqqyQmJlJcXExzc/Pp30jekpa2Dv6w8QCPry7n+c2VuMPbJ+fy2aunccWMMWc0LUJ7h7OtsoHXy2tZU17LmopaHl61/djonGMykpgyJv1Yc0+ASaNH8r4F43n75FwuKMk5awdtEZGo2QMURmwXhPuOY2bvAj4HXOrux+Z4cfc94et2M1sJzANOCILu/jDwMEBpaWnfmj3I2a1yE6z7dRAAD64L9iWkQFtT1zkZ44JAmDc9GJEzrzMgnuGk5y9/D5b/E0y/NgiBGqxFZMiKnX+BnubJXTQtXryYO+64g6qqKp5//nmWLl3K6NGjSUxMZMWKFezatWvQahvOth5sYGlZOU++WkH1kRbyM5L51DsmcUtp4XETlZ+J+Dhjyph0poxJ59bS4N91za3trN93OAiG5bVsOtDA2ybmcPGkXC6enMvYUVEe0lpEznargclmVkIQAG8D3h95gpnNA34ILHL3gxH7s4BGdz9qZrnARQQDycjZrO1oMO9de2swh15qdt+nHzi4IQx/vw7mzcOCOfYW/SvMuA5G5gfTLlRuDJaDG6FyA5QtOTEgjp4OhQuh5O1wznm9f6L30nfgmc/D9OvgvUsUAkWGuNgJgoNo5syZ1NfXM27cOMaOHcsHPvABrr32WmbPnk1paSnTpk0b7BKHrPYOZ29tEzs6J0ePmCx9e9UREuKMd04fzW3zx3PJlLwBaXaZnBjPeeOzOG98VtQ/S0SGHndvM7NPAssJpo9Y4u7rzOwBoMzdnwK+AYwEfhH2H++cJmI68EMz6wDiCPoIru/xg2TguUPtbji4Hg6sC5aD64Pmm8cmOwcS04JJzrPCidWPLeF2Snj/OLi+68lf1SbAoOgiuOobwRO5jLHHf352SbBMvaprX0d7EBA7g2HlJti/FlY8CCuAxFQYvxCK3w4ll8DYuRDfwz8PX/wWPPdFmHED3PwjhUCRYcDch0drkdLSUi8rKztu34YNG5g+ffogVTTwhvP3PdzcyhvldeyoamBHVSO7qo+wo/oI5TWNxw30kpIYT1FOKiW5acwtzOTG88YxOv0M5jMSkbOSmb3q7qWDXcdQ0dM9Us6AOxyphOqtxwe+gxvg6OGu8zLHw+iZwYTnY2ZAfBLUlcOhXUFgrN0dhLTIawBGpENSOtTvBYsLwt+M64Mncelj+uc7NNbAzhdh5wuw44UgJHZ+dtGFYTB8O+TPgT/+O/z+X4LpG258uOegKCJnhb7cH/V/spyVqhqOsnpHDX/aUcPqnTVs2HeYsNsdKYnxFOemMXVMOlfOzKc4J5XinDSKc9MYnZ6k0VdFROTMdXRA/T6o2d5t2RG8th7pOjd5FIyZBXMWB4Fv9Myg+WVv++M11XaFws6AeKQyCIDTr4WRo/v/+6VmB01KZ1wXbDdUBqGwMxhueSbYPyIdWuph1nvhxh8qBIoMI/q/WQadu1NxqInVO2v4844a/ryzhu2VwQ02OTGO88Zncdc7J1NalM3kMSMV9kREpH90dARP3aq3Qc228DUMfId2QlvEQG5xiZBVDNkToPji4DV7QhD4Ms7pe5+/SCmZwTJ2zpl+o7duZB7MuilYAA7vC58Yrgr6H176GYVAkWFG/0fLW+bu7KtrZk15La9XBAOjbD0Y9MtLGRFMvJ4yIp6UxHiSE7tekxPjjq2XH2pk9Y4a9tYFN9uM5ATmF2ezuLQtQoGdAAAgAElEQVSQ+SXZzDpnVL9O3C4iIjHGHRoOhkFva0ToCwNf5EAq8UlhP7uJMOldXWEvewKMKoC4tz7K9JCTMRbm3BIsIjIsDfsg6O4x8fRoIPp61jW2sqaia5qE18vrqGoIRjTvnGD9ndNG4zhNrR00t7bT3NpOU0s7h5tbaWpppznc3xQuuSOTWFCSzceLs1lQks3UMemaLF1EZKhrbQ5C02AMKNJUCxVlUP4KlP8J9r5+fB+8uATIKoGciTDhMsiZADmTgvCXMQ7i9OOjiMSGYR0Ek5OTqa6uJicnZ1iHQXenurqa5OT+HRTlYH0zz64/wOodNaypqGNHVVd/iIl5aVwyJZe5hZnMKchk+tj0Ps/HFyshXURkWHMP+raVrw6CV8Wfg1EpcUgfGzxJO7YUhku4nZJ55p9dsx3K/xwGvz8HA7bgwSArY2bB7FuC+fOyJwahb9R4NXEUEWGYB8GCggIqKiqorKwc7FKiLjk5mYKCgjN+n4pDjSxfd4Dfrd1H2a5DuMPo9CTmFmby3vMLmFuYyeyCUWQkn/mvvAqBIiJDUGsz7FsThL7yP0HFamg4EBxLTIOC8+Hie8Dioa4iGCVzz6uw/inoaD3+vZIygkCYng8j0oJJ0RMjloQUSEwOpjhISA73JYfhL/z8I+E9PmkUFM6HmTdC4QUw7nxIGjmwfzYiIkPIsA6CiYmJlJSUDHYZZ70dVUd4eu0+frd2P29U1AEwLT+du985matmjWXKmJEKbSIisax8Naz7VfC0b+/rXYEuqzhoXlkwPwhfo2ec/GlbRwccOdgVDusqoDZ8bdgP9fuhtTEImq1NQd+99paT15Q9IejHV7ggmBw9b5qadYqI9MGwDoLSM3dn04F6nn5zP79bu59NB+oBOLcwk88smsaiWfmU5KYNcpUiInLW2PMqrP4RjDsPFv5tEPoKF/RtWoO4uODJX3o+FPRyCsiO9iAUdgbDzvWMc6IzpYKISAxREBzG3J3qIy3srDrCzupGdlYFk7Cv21PHzupGzGB+cTZfeM8MFs3K55zMlMEuWUREzkbnfRBKPwoJIwb2c+Pig+adauIpItLvohoEzWwR8O9APPAjd3+o2/EiYAmQB9QAt7t7RXjs68A1QBzwLHC3D8TQmEOIu9PU2k5dUyt7DjWxo+oIu6ob2VF9hF3VR9hV1Uj90bZj58fHGYVZKUzMG8kdl0zg3TPyyUtPGsRvICIiQ8IItRIRERluohYEzSwe+B5wBVABrDazp9x9fcRp3wQedfefmNnlwNeAD5rZ24CLgM6ZVV8ELgVWRqves0l5TSNlu2o4dKSVuqYTl9rGFuqa2jjc1EpLe8dx13aGvaKcNEqLsinKSaU4N42SnDTGZaWQGK/+EyIiIiIisS6aTwQXAFvdfTuAmT0OXA9EBsEZwL3h+grg1+G6A8nACMCAROBAFGsdVO7Ohn31LF+3n2fWH2DDvsPHHc9ITmBUaiKjUoJlWn4GGSld26NSEhmbmUxxThoFCnsiIiIiInIa0QyC44DyiO0K4IJu56wBbiJoPnojkG5mOe7+spmtAPYRBMHvuvuGKNY64No7nFd3HeKZdftZvn4/5TVNmEFpURafv2Y6l0zJY3R6EunJicRrgnUREREREelHgz1YzH3Ad83sI8AqYA/QbmaTgOlA58R4z5rZ2939hciLzexO4E6A8ePHD1jRb9XRtnZe2lrN8nX7eW7DAaoaWhgRH8dFk3L4u8sm8a7pY9RnT0REREREoi6aQXAPUBixXRDuO8bd9xI8EcTMRgI3u3utmd0BvOLuDeGxp4ELgRe6Xf8w8DBAaWnpWTmQTH1zKys2VbJ83X5WbjzIkZZ2RiYlcNnUPK6cmc9lU/NI74fJ2UVERERERHormkFwNTDZzEoIAuBtwPsjTzCzXKDG3TuAzxKMIAqwG7jDzL5G0DT0UuBbUay1X1XWH+XZ9Qd4Zv1+XtpaTUt7BzlpI7j23HO4cmY+b5uUQ1JC/GCXKSIiIiIiMSpqQdDd28zsk8Bygukjlrj7OjN7AChz96eAy4CvmZkTNA39RHj5E8DlwJsEA8f8zt3/N1q19ofd1Y0sX7ef5ev28+ruQ7hDYXYKH7qwiCtn5XPe+Cz19RMRERERkbNCVPsIuvsyYFm3fV+IWH+CIPR1v64d+Hg0aztT7s76fYdZvu4Az6zbz8b99QBMH5vB3e+czJUz85mWn46Zwp+IiIiIiJxdBnuwmCHp0JEW/vHJN3h2/QHMYH5RNp+/ZjpXzsynMDt1sMsTERERERE5JQXBPlq9s4a7HnuNqoaj/OOiqdxaWkjuSI30KSIiIiIiQ4eCYC+1dzjfX7GVf3tuM4XZqfzyby9idsGowS5LRERERESkzxQEe+Hg4Wbu+Z/XeWlbNdfPPYcHb5ilKR9ERERERGTIUhA8jZWbDvL3S9dwpKWNr988h1tKCzQAjIiIiIiIDGkKgifR2t7BN5/ZxA+f3860/HT+5/0LmTQ6fbDLEhEREREROWMKgj0or2nkU4+9xuvltXzggvH883tmkJyoCeBFRERERGR4UBDsZtmb+/jMk28A8L33n8c1c8YOckUiIiIiIiL9S0Ew1Nzazpd/u56f/Wk3cwsz+c775mlOQBERERERGZYUBENHWzt4fnMlH790Ave9eyqJ8XGDXZKIiIiIiEhUKAiGRqUmsvyeS0hL0h+JiIiIiIgMb3rsFUEhUEREREREYoGCoIiIiIiISIxREBQREREREYkxCoIiIiIiIiIxRkFQREREREQkxigIioiIiIiIxBgFQRERERERkRijICgiIiIiIhJjFARFRERERERijIKgiIiIiIhIjFEQFBERERERiTEKgiIiIiIiIjFGQVBERERERCTGKAiKiIiIiIjEGAVBERERERGRGKMgKCIiIiIiEmMUBEVERERERGKMgqCIiMgAM7NFZrbJzLaa2f09HL/XzNab2Rtm9nszK4o49mEz2xIuHx7YykVEZLhQEBQRERlAZhYPfA+4CpgBvM/MZnQ77TWg1N3nAE8AXw+vzQa+CFwALAC+aGZZA1W7iIgMHwqCIiIiA2sBsNXdt7t7C/A4cH3kCe6+wt0bw81XgIJw/UrgWXevcfdDwLPAogGqW0REhhEFQRERkYE1DiiP2K4I953Mx4Cn+3qtmd1pZmVmVlZZWXkG5YqIyHCkICgiInKWMrPbgVLgG3291t0fdvdSdy/Ny8vr/+JERGRIUxAUEREZWHuAwojtgnDfcczsXcDngOvc/WhfrhURETmdqAbBXoyKVhSOhvaGma00s4Jw/zvM7PWIpdnMbohmrSIiIgNkNTDZzErMbARwG/BU5AlmNg/4IUEIPBhxaDnwbjPLCgeJeXe4T0REpE+iFgR7OSraN4FHw1HRHgC+Bsc6yc9197nA5UAj8Ey0ahURERko7t4GfJIgwG0Alrr7OjN7wMyuC0/7BjAS+EX4g+hT4bU1wJcJwuRq4IFwn4iISJ8kRPG9j42KBmBmnaOirY84ZwZwb7i+Avh1D+/zXuDpiNHTREREhjR3XwYs67bvCxHr7zrFtUuAJdGrTkREYkE0m4b2ZmSzNcBN4fqNQLqZ5XQ75zbgsahUKCIiIiIiEoMGe7CY+4BLzew14FKCDu/tnQfNbCwwm5P0f9DQ2CIiIiIiIn0XzSB42pHN3H2vu9/k7vMIRkbD3WsjTrkV+JW7t/b0ARoaW0REREREpO+iGQR7Myparpl11vBZTuzz8D7ULFRERERERKRfRS0I9nJUtMuATWa2GRgDfKXzejMrJnii+Hy0ahQREREREYlF0Rw1tDejoj0BPHGSa3dy4uAyIiIiIiIicoYGe7AYERERERERGWAKgiIiIiIiIjFGQVBERERERCTGKAiKiIiIiIjEGAVBERERERGRGKMgKCIiIiIiEmMUBEVERERERGKMgqCIiIiIiEiMURAUERERERGJMQqCIiIiIiIiMUZBUEREREREJMYoCIqIiIiIiMQYBUEREREREZEYoyAoIiIiIiISYxQERUREREREYoyCoIiIiIiISIxREBQREREREYkxCoIiIiIiIiIxRkFQREREREQkxigIioiIiIiIxBgFQRERERERkRhz2iBoZp8ys6yBKEZERERERESirzdPBMcAq81sqZktMjOLdlEiIiIiIiISPacNgu7+eWAy8J/AR4AtZvZVM5sY5dpEREREREQkCnrVR9DdHdgfLm1AFvCEmX09irWJiIiIiIhIFCSc7gQzuxv4EFAF/Aj4B3dvNbM4YAvwj9EtUURERERE5PRaW1upqKigubl5sEuJquTkZAoKCkhMTHzL73HaIAhkAze5+67Ine7eYWbvecufLCIiIiIi0o8qKipIT0+nuLiY4Tq0ibtTXV1NRUUFJSUlb/l9etM09GmgpnPDzDLM7IKwiA1v+ZNFRERERET6UXNzMzk5OcM2BAKYGTk5OWf81LM3QfA/gIaI7YZwn4iIiIiIyFllOIfATv3xHXsTBC0cLAYImoTSuyalIiIiIiIichbqTRDcbmZ3mVliuNwNbI92YSIiIiIiIkNJbW0t3//+9/t83dVXX01tbW0UKjq53gTBvwHeBuwBKoALgDujWZSIiIiIiMhQc7Ig2NbWdsrrli1bRmZmZrTK6tFpm3i6+0HgtgGoRUREREREZMi6//772bZtG3PnziUxMZHk5GSysrLYuHEjmzdv5oYbbqC8vJzm5mbuvvtu7rwzeL5WXFxMWVkZDQ0NXHXVVVx88cW89NJLjBs3jt/85jekpKT0e629mUcwGfgYMBNI7tzv7h/t92pERESGGDObCFS4+1EzuwyYAzzq7gPbxkdERI7zL/+7jvV7D/fre844J4MvXjvzpMcfeugh1q5dy+uvv87KlSu55pprWLt27bFpHpYsWUJ2djZNTU3Mnz+fm2++mZycnOPeY8uWLTz22GM88sgj3HrrrTz55JPcfvvt/fo9oHdNQ38K5ANXAs8DBUB9v1ciIiIyND0JtJvZJOBhoBD4+eCWJCIiZ4MFCxYcN9fft7/9bc4991wWLlxIeXk5W7ZsOeGakpIS5s6dC8D555/Pzp07o1Jbb0b/nOTut5jZ9e7+EzP7OfBCb97czBYB/w7EAz9y94e6HS8ClgB5BHMV3u7uFeGx8cCPCG6oDlzt7jt797VEREQGTIe7t5nZjcB33P07ZvbaYBclIhLrTvXkbqCkpaUdW1+5ciXPPfccL7/8MqmpqVx22WU9zgWYlJR0bD0+Pp6mpqao1NabJ4Kt4Wutmc0CRgGjT3eRmcUD3wOuAmYA7zOzGd1O+yZB85k5wAPA1yKOPQp8w92nAwuAg72oVUREZKC1mtn7gA8Dvw33JQ5iPSIiMkjS09Opr++58WRdXR1ZWVmkpqayceNGXnnllQGu7ni9eSL4sJllAZ8HngJGAv/ci+sWAFvdfTuAmT0OXA+sjzhnBnBvuL4C+HV47gwgwd2fBXD3yAntRUREziZ/RTDC9lfcfYeZlRB0qxARkRiTk5PDRRddxKxZs0hJSWHMmDHHji1atIgf/OAHTJ8+nalTp7Jw4cJBrPQ0QdDM4oDD7n4IWAVM6MN7jwPKI7Y7p56ItAa4iaD56I1AupnlAFMInkD+EigBngPud/f2Pny+iIhI1Ln7euAugPCH03R3/9fBrUpERAbLz3/eczfxpKQknn766R6PdfYDzM3NZe3atcf233ffff1eX6dTNg119w7gH6P26XAfcGnYl+JSgrkK2wkC6tvD4/MJAuhHul9sZneaWZmZlVVWVkaxTBERkZ6Z2UozyzCzbOAvwCNm9n9Pc80iM9tkZlvN7P4ejl9iZn8xszYze2+3Y+1m9nq4PNW/30ZERGJFb/oIPmdm95lZoZlldy69uG4PwUAvnQrCfce4+153v8nd5wGfC/fVEjw9fN3dt7t7G0GT0fO6f4C7P+zupe5empeX14uSRERE+t0odz9M0MLlUXe/AHjXyU7uZR/63QQ/gPb0s3KTu88Nl+v64wuIiEjs6U0fwcXh6yci9jmnbya6Gpgc9pXYQzAp/fsjTzCzXKAmfPL4WYIRRDuvzTSzPHevBC4HynpRq4iIyEBLMLOxwK2EP2qexmn70HeOkm1mHf1erYiICL14IujuJT0sp+0rGD7J+ySwHNgALHX3dWb2gJl1/oJ5GbDJzDYDY4CvhNe2EzQL/b2ZvQkY8Mhb+H4iIiLR9gDBvW6bu682swnAiRNDdempD/24Pnxectgt4hUzu6Hv5YqIiPTiiaCZfain/e7+6OmudfdlwLJu+74Qsf4E8MRJrn0WmHO6zxARERlM7v4L4BcR29uBm6P4kUXuvicMnH8wszfdfVv3k8zsTuBOgPHjx0exHBERGYp600dwfsTyduBLgPokiIiIAGZWYGa/MrOD4fKkmRWc4pLT9qE/FXffE75uB1YC805ynvrRi4jISZ32iaC7fypy28wygcejVpGIiMjQ8mOCQV1uCbdvD/ddcZLzT9uH/mTC6Ska3f1o2M/+IuDrZ1C7iIgMopEjR9LQMDhTpvfmiWB3Rwjm9hMRERHIc/cfu3tbuPwXcNJHcL3pQ29m882sgiBc/tDM1oWXTwfKzGwNsAJ4KJzHUEREpE9600fwfwlGCYUgOM4AlkazKBERkSGk2sxuBx4Lt98HVJ/qgl70oV9N0GS0+3UvAbPPtGAREYmO+++/n8LCQj7xiWDChS996UskJCSwYsUKDh06RGtrKw8++CDXX3/9IFfau+kjvhmx3gbscveKKNUjIiIy1HwU+A7wbwQ/nL5EMAegiIgMpqfvh/1v9u975s+Gqx466eHFixdzzz33HAuCS5cuZfny5dx1111kZGRQVVXFwoULue666zCz/q2tj3oTBHcD+9y9GcDMUsysuHOOIxERkVjm7rvoNoiamd0DfGtwKhIRkcEyb948Dh48yN69e6msrCQrK4v8/Hw+/elPs2rVKuLi4tizZw8HDhwgPz9/UGvtTRD8BfC2iO32cN/8qFQkIiIy9N2LgqCIyOA6xZO7aLrlllt44okn2L9/P4sXL+ZnP/sZlZWVvPrqqyQmJlJcXExzc/Og1BapN0Ewwd1bOjfcvcXMRkSxJhERkaFucNv7iIjIoFm8eDF33HEHVVVVPP/88yxdupTRo0eTmJjIihUr2LVr12CXCPRu1NDKzlHMAMzseqAqeiWJiIgMeX76U0REZDiaOXMm9fX1jBs3jrFjx/KBD3yAsrIyZs+ezaOPPsq0adMGu0Sgd08E/wb4mZl9N9yuAD4UvZJERETOfmZWT8+Bz4CUAS5HRETOIm++2TVITW5uLi+//HKP5w3WHILQuwnltwELzWxkuD141YqIiJwl3D19sGsQERF5q07bNNTMvmpmme7e4O4NZpZlZg8ORHEiIiIiIiLS/3rTR/Aqd6/t3HD3Q8DV0StJRERERETkrXEf/t20++M79iYIxptZUueGmaUASac4X0REREREZMAlJydTXV09rMOgu1NdXU1ycvIZvU9vBov5GfB7M/sxQQf4jwA/OaNPFRERERER6WcFBQVUVFRQWVk52KVEVXJyMgUFBWf0Hr0ZLOZfzWwN8C6C0dGWA0Vn9KkiIiIiIiL9LDExkZKSksEuY0joTdNQgAMEIfAW4HJgQ9QqEhERERERkag66RNBM5sCvC9cqoD/Aczd3zFAtYmIiIiIiEgUnKpp6EbgBeA97r4VwMw+PSBViYiIiIiISNScqmnoTcA+YIWZPWJm7yQYLEZERERERESGsJMGQXf/tbvfBkwDVgD3AKPN7D/M7N0DVaCIiIiIiIj0r9MOFuPuR9z95+5+LVAAvAZ8JuqViYiIiIiISFT0dtRQANz9kLs/7O7vjFZBIiIiIiIiEl19CoIiIiIiIiIy9CkIioiIiIiIxBgFQRERERERkRijICgiIiIiIhJjFARFRERERERijIKgiIiIiIhIjFEQFBERERERiTEKgiIiIiIiIjFGQVBERERERCTGKAiKiIiIiIjEGAVBERERERGRGBPVIGhmi8xsk5ltNbP7ezheZGa/N7M3zGylmRVEHGs3s9fD5alo1ikiIiIiIhJLEqL1xmYWD3wPuAKoAFab2VPuvj7itG8Cj7r7T8zscuBrwAfDY03uPjda9YmIiIiIiMSqaD4RXABsdfft7t4CPA5c3+2cGcAfwvUVPRwXERERERGRfhbNIDgOKI/Yrgj3RVoD3BSu3wikm1lOuJ1sZmVm9oqZ3RDFOkVERERERGLKYA8Wcx9wqZm9BlwK7AHaw2NF7l4KvB/4lplN7H6xmd0ZhsWyysrKAStaRERERERkKItmENwDFEZsF4T7jnH3ve5+k7vPAz4X7qsNX/eEr9uBlcC87h/g7g+7e6m7l+bl5UXlS4iIiIiIiAw30QyCq4HJZlZiZiOA24DjRv80s1wz66zhs8CScH+WmSV1ngNcBEQOMiMiIiIiIiJvUdSCoLu3AZ8ElgMbgKXuvs7MHjCz68LTLgM2mdlmYAzwlXD/dKDMzNYQDCLzULfRRkVEREREROQtitr0EQDuvgxY1m3fFyLWnwCe6OG6l4DZ0axNREREREQkVg32YDEiIiIiIiIywBQERUREREREYoyCoIiIiIiISIxREBQREREREYkxCoIiIiIiIiIxRkFQREREREQkxigIioiIiIiIxBgFQRERkQFmZovMbJOZbTWz+3s4fomZ/cXM2szsvd2OfdjMtoTLhweuahERGU4UBEVERAaQmcUD3wOuAmYA7zOzGd1O2w18BPh5t2uzgS8CFwALgC+aWVa0axYRkeFHQVBERGRgLQC2uvt2d28BHgeujzzB3Xe6+xtAR7drrwSedfcadz8EPAssGoiiRURkeFEQFBERGVjjgPKI7YpwX7SvFREROUZBUEREZBgyszvNrMzMyiorKwe7HBEROcsoCIqIiAysPUBhxHZBuK9fr3X3h9291N1L8/Ly3lKhIiIyfCkIioiIDKzVwGQzKzGzEcBtwFO9vHY58G4zywoHiXl3uE9ERKRPFARFREQGkLu3AZ8kCHAbgKXuvs7MHjCz6wDMbL6ZVQC3AD80s3XhtTXAlwnC5GrggXCfiIhInyQMdgEiIiKxxt2XAcu67ftCxPpqgmafPV27BFgS1QJFRGTY0xNBERERERGRGKMgKCIiIiIiEmMUBEVERERERGKMgqCIiIiIiEiMURAUERERERGJMQqCIiIiIiIiMUZBUEREREREJMYoCIrI/2/vzuPjOut7j39+s0ij3dplW97txElsE8AJSUiICVvCpUmBeyEp7Yv2lguUpfRSWugOKbmFXval8ApLgV4gpYGEUEILzR5IIM5mO4s32Y4ly1pt7SNpZp77x3NkjRYrka3RjGa+79drXnPmnOOj55ljzaPvPM95joiIiIgUGAVBERERERGRAqMgKCIiIiIiUmAUBEVERERERAqMgqCIiIiIiEiBURAUEREREREpMAqCIiIiIiIiBUZBUEREREREpMAoCIqIiIiIiBQYBUEREREREZECoyAoIiIiIiJSYDIaBM3sajPba2YHzOwjs2xfY2Z3mdkuM7vXzJqnba80s1Yz+1ImyykiIiIiIlJIMhYEzSwMfBm4BjgfuMHMzp+226eA7zjntgE3Av8wbfvfA/dnqowiIiIiIiKFKJM9ghcDB5xzLc65MeAW4Lpp+5wP3B0s35O+3cxeCjQCP89gGUVERERERApOJoPgSuBo2uvWYF26J4E3BctvBCrMrNbMQsCngQ9lsHwiIiIiIiIFKduTxXwIuNLMHgeuBNqAJPAe4E7nXOtc/9jM3mlmO81sZ1dXV+ZLKyIiIiIikgciGTx2G7Aq7XVzsO4U59wxgh5BMysH3uycO2lmlwJXmNl7gHKgyMwGnXMfmfbvbwZuBti+fbvLWE1ERERERETySCaD4CPAJjNbhw+A1wO/k76DmdUBvc65FPAXwDcBnHNvS9vn94Ht00OgiIiIiIiInJmMDQ11ziWA9wH/CTwD/MA595SZ3Whm1wa77QD2mtk+/MQwN2WqPCIiIiIiIuJlskcQ59ydwJ3T1v1t2vKtwK3Pc4xvAd/KQPFEREREREQKUrYnixEREREREZFFpiAoIiIiIiJSYBQERUREZE6Huof4fw8fYSyRynZRRERkgSgIioiIyJxuf7yNv759D6/81L3c8pvnGE8qEIqILHUKgiIiIjKnP3n1Jr71BxdRV17ER360m6s+fS//tvMoCQVCEZElS0FQRERE5mRm7Di3gdvf+3K+8fbtVJVE+bNbd/Hqz9zHbY+3kky5bBdRRETmSUFQREREXhAz41XnNfKT913Ozb/3UkqKIvzvf32S13z2Pn78RJsCoYjIEqIgKCIiIvNiZrz2giZ++v7L+crbXkIkZHzglie4+nP389Nd7aQUCEVEcl5GbygvIiIi+SsUMq7ZupzXXdDEnXva+dx/7ee933uMzU0VvO2SNew4p55VNaXZLqaIiMxCQVBERETOSihkvGHbCq7Zspx/33WML959gL+5fQ8AGxvK2XFOPa/c3MD2tdUUR8JZLq2IiICCoIiIiCyQcMi47sKVXPuiFRzsGuLevZ3cu7eL7zx0hK8/eIjSojAv31jHjnPr2XFuAyuXlWS7yCIiBUtBUERERBaUmbGxoZyNDeW844r1DI0meOhgD/cEwfAXT3cAcE5jOTvObeDlG+tYXVPK8qoYsah6DEVEFoOCoIiIiGRUWXGEV5/fyKvPb8Q5x8GuQe7d28U9ezv5518e4ub7W07tW10aZXlVCSuWxWiqik0uV/rnxkqFRRGRhaAgKCIiIovG9xZWsLGh4lRv4a7WPtr7Rmjvi3Ps5AjH++K0nYyz88gJTg6PzzjGiqoY5zZVcE5TBec2VnBOYwUbG8oVEEVE5kFBUERERLKmrFiTtIkAABwASURBVDjCpRtqT7t9ZCx5KiROBMWWrkH2dgzyywM9jCVTAIQM1taWcU5jBec2+cc5jRWsrS0lEtbdskREplMQFBERkZxVUhRmfX056+vLZ2xLJFMc7hlmX8cAzx4fYN/xAfZ1DPDzp48zcSvDkEFlSZSKWITKWJTKWLCctm7idWUsQkNljPV1ZSwrLVrkmoqILC4FQREREVmSIuHQqUlpXr91+an18fEkBzoH2dcxQEvXEP3xcfpHxumPJxiIj3OkZ5iBuH89OJqY9djLSqOsrS1jXZ1/rK0rY11tGWvrSqmIRReriiIiGaMgKCIiInklFg2zZWUVW1ZWPe++yZRjMJ6gPz5O38g47X1xDncPcahniMPdQzzc0sNtj7dN+Td15cWsqytlXV0Zmxoq2NhYzjmNFayoimFmmaqWiMiCUhAUERGRghUOGVWlUapKo6yCWcPjyFiSI70+GB7qHj4VFO9+tosf7Gw9tV95cYSNDeWcEwTDTY0VbGooZ7kCoojkIAVBERGRRWZmVwOfB8LA151zn5i2vRj4DvBSoAd4q3PusJmtBZ4B9ga7Puyce/dilbtQlRSF2dxUyeamyhnbTgyNsT8Yhrq/Y4B9HYPc/WznlIBYURxhY2M5jRUxwiEjFDLCBqGQEQmZX2f+ORwywmZEIyFW15Syvq6MDQ3l1JYVKUyKyIJSEBQREVlEZhYGvgy8BmgFHjGzO5xzT6ft9ofACefcRjO7Hvgk8NZg20Hn3IWLWmg5reqyIi5eV8PF62qmrO8dGvPhsHMwCIgDtHQPkkw5Us4PST31cI5U8JxM+uexRIrExIw3QGUswoaGctbXlbOhoYz1deVsbChjdU0ZRRHNiioi86cgKCIisrguBg4451oAzOwW4DogPQheB3w0WL4V+JKpO2hJqSkr4pL1tVyy/vS3xphLKuVoOzlCS/cQBzsHaeke5GDnEA8e6OKHj032NoZDxuqaUhoqiomEjXAoRNggHAr53sbwZK9j2IxI2IiGQzRWxmiuLqG5upRV1SXUVxSrx1GkwCgIpnvon6DxAlj1MojGsl0aERHJTyuBo2mvW4GXnW4f51zCzPqAiUSxzsweB/qBv3bOPTDbDzGzdwLvBFi9evXClV4WRShkrKopZVVNKVeeUz9l20B8nEPdQxzsGqSlyz/3DI4FvYhJkilHIjnZ25hMORKpFMmkI5FyjCVTnBwen3LM4kiIlWnBsLm6lObqElbV+Elxqko0U6pIvlEQnDByEn7xt5Aah0gMVl8C666E9VfC8gshFM52CZe25Dh074fju+H4ruB5N5TWwouu94+q5myXUkQk17UDq51zPWb2UuB2M7vAOdc/fUfn3M3AzQDbt29307fL0lURi7KteRnbmped8TFGxpK0nhim9cQIrSeGORo8t54YYXfrSU6kBUUzuGBFJZeur+XSDbVctLZGt9AQyQMKghNKlsGft8CRX8Gh+6DlPrjrY3AXEKuCtVfA+h3+UbvRfyrK7OL90PHU1NDX+QwkR/32SAwazofz3gA9LXD338PdH/fv7YVv8+ujJdmsgYhIJrUBq9JeNwfrZtun1cwiQBXQ45xzwCiAc+5RMzsInAPszHipJa+UFIX9rKaNFbNuHxxN0HZihKO9w+w51sdDB3v49q+O8LUHDhEOGVtXVnHphlou21DL9jU1lBTN/YV5IpmivS/OkZ5hnusd5kjvEEd7hxlLOM5fUcnWlVVsWVlJU6VmWBVZLObblKVv+/btbufOBW4HBzvh0P3Qcq8Phyef8+srVviewrVXwPIXQf25EC7gb8acg9ad8NSPYN9/QG/L5LbSWmjaCk3bgsdWH6TDad9B9B6CJ2+BJ74Hfc9BcSVseZMPhc0XKXSLyAxm9qhzbnu2y3EmgmC3D3gVPvA9AvyOc+6ptH3eC2x1zr07mCzmTc65t5hZPdDrnEua2XrggWC/3rl+ZkbaSCk48fEkjx05wa8O9vBQSw9PHj1JIuWIho0LVy3j0vW1bF9bw/BYkud6h3zgC4Jf24mRKZPfRMPGqupSQiGjpWuQiU21ZUVcsLKKrSsr2bLC3wuyubpE4VDkBZpP+6ggOB+9hyZD4aH7YbjHrw8XQf3myaDTtBWatviexHzlHBx7DJ66DZ66HfqO+vdhw1XQvH3yvahY/sKDXCoFRx70gfDpH8P4sA+NF/4ObLseqlYuXPmHe6H1ETj6azj6G+jeBy+6Aa78cygqW7ifs1SNj8Bj34FVF8OKF2e7NCIzLOUgCGBmrwc+h799xDedczeZ2Y3ATufcHWYWA/4FeDHQC1zvnGsxszcDNwLjQAr4O+fcT57v5ykISiYMjSbYeeQEvzrYzcMHe9jd1kda1mNZaZTVNaWnHmtq/TWPa2rLaKr0t9IAGB5L8Ez7AHva+vzjWD/7OwZOBcfKWIQtK6u4YEUly0qLCKfddiMS3I7Dvw5NWW9mmMHEXyETYdKY/NNk8tloXlbCuroyImHNwipLl4LgYkiloOcAdOyG9l2TwyCHuib3WbYmrTdsC5Q3+SGP0RhES/1ypMT3Ji6Fb7qc83V86jb/OHEYQlEf/i54I2x+/cKF39EBHwaf+B4c+SVgsO4Vfkhp1UqoXOmvKaxc4d/X8ByjnFMp6N4bhL4g/PXs99tCEX+Oyhpg/39CZTO87iY4/7qlcU4y4dD98JMP+J5dC8El74FX/qUCsuSUpR4EF5uCoCyG/vg4u1v7qCqJsqqm9KwmmImPJ9nXMcDutj72tPXz1LE+nm0fYCyZWsASz1QUDrGxoZzNyys4r6mSzcsr2NxUSX1FcUZ/rshCURDMpoGOmROi9BwA5nifLRwExCAYRkugtAZWX+qvm8vmLKbOQefTsOdHPvz1HvTlXb/Dh7/z3gAl1ZktQ28LPPF9ePbf/fDcscGp2y0MFU1BOEwLifF+H/pad8Jon9+3tNa/n6suhuagt6uo1G977mH46Yd8uF//Snj9/4W6TZmt23Td++HY4/46ymhp8KVBiV+esq504Ycjj5yAn/8NPP4vUL0OXvd/fDh+9Fv+S403fBY2vmphf+ZCcw6eewjGhqF2AyxbrYmenk8qBfGT/vwP98JIr18eG/I9w4kR/zzlMQyJ+ORrC/nPrNJa/3lQWgMlNWnraibXRYoWpNgKgvOTM22kyFlIpRzjqdSUezAm0p5Tp16nTq2f/meuc+CCv8kmtjn8fR2f6x3i2fYBnjk+wN7j/XT0j576d7VlRadC4eYm/7yhoYzSIk23IblFQTDXjA76yVJGemf5Q2oYxuMz1/W3Q9uj4JI+AKx6WTBZzTxnMR0bgo6npwbT3oPgXuA3as7BaL//Q2/tFf7avc2/BWVndl+ks+YcxPugvw362qC/NXg+lrbc5t9HzN8OpPmiyfBXs37unr5kAnZ+w09eMz4Cl70fXvGhzPaGOQeHH4SHvuSvsXyhQhGIlsHGq+Cid8Cal59ZL6Zz8PTtcOef++HOl70frvzwZEA+/Ev4yR/7LzS2Xe8DYrbO/1yOPAR33QjP/WpyXbjIn/Pajf5RtylY3uSDyener8ToZCg69dzjl8cGg9/Z4WlBaZZ1yTH/+zs9xEdLTrOuZOqogbn2iRT7ck4pw/BkORJp5RmP+y9Dhk9MrctE6Hu+zwMLz/xiIr0sqURw3OD448OnP1ZRBVz7edjy5vmf4/QiKQjOS063kSI5qndojGeP9/Ns+wB7jw/w7PF+9nYMEB+f/Mxsri5hU0M5mxor2FhfzsbGcjY2lFO5gLOqOucYGE3Q0RenvS/O8b44x/v9ckd/nNU1pVyzpYnta2tODbeVwqUgmC/i/VNnMe0M5hFIn8V03ZX+j1uz5++NjFX5Yap158yvN6luE5x3HZTXP/++ucA5/0duOAqxyjM7xmCnv53Ik9/3w0Wv/gc477cWdrhoctxfX/nQF6H9Sd9zctH/8sNSXXJqD8xsvTKJET8U+ek7fI9O/WYfCLe99YXXu68NfvqnsO9n/guGa7/gJ0CabjwOD3wKHvys/3909Sdg6//IjeGz7bv8zLP7fw7ljfCKP/NfAPQc8D2sPQf9UODeQ/72MBNiy3worFrpf9cmgsxwD4wPnf7nhYvmCGzT1oWL/Gy5s5272XrZXDJz71MkltY7Vz21l660dmovXkm1//LjTIevj4+cJkgHQXHbW8762lMFwfnJyzZSJAuSKceRniH2Hh/gQOcg+4PHwa5BxhKTAbGpMsamxnI21PtgWBGLzOi5TDk3o3czlXLEE0mO941yvH/Eh76+OENjM9uHuvIi6sqLOdQ9xGgiRX1FMVdf0MQ1W5u4eG2NrnUsUAqC+Sp9FtOW+/wMm+AnZEklYahzct9lq6dNXrMVqlblxh/uS8mRh+DOD0HHHtjwKj9ctHbD2R0z3g+PfRse/qrvxazdCJe+z99L8UxumzE27GdsfeTrflhptMz/oX3RO/y1qbNJpXzP5399zPfmXPVX8LI/mvtaS/C3Bbnjj6FtJ2x8Nfy3z0D1mvmXeSF0H4B7bvJ1jy2Dy/8ELn7XZE/mdMmE/53pPuBDYs9+/9zf7sPtlFBUffqhjZkcpp0cn9qrN1ePY2LU9wqeLohOGVJcknczGysIzk9BtJEiWZRMOY72DqeFQx8UD3QOMjxLiJtLOGQ0VBTTVBVjeVWMxkr/3FRV4p8rYzRUFlMc8aPDhkYT3LO3k5/tPs7dz3YyMp6ktqyI117QxOu3NnHJ+lqiCoUFQ0GwEDgHJw75QHj4Af/H3kTga9zi74soCyOZ8CHrnpv8cLvL/hiu+OD8h4v2tcLDX/GzcY72w5rL4bL3wabXQWiBPqDbHoVHvgl7bvVlXXWJD4TnX+tDA0Dns36o59Ff+2sh3/BZqFn3wn9GKgm/+ZofhomDq/4aXvbuxbsWr68V7vskPP5dX6dL3uOHs+r/fEFREJyfgmsjRXJEKuVo748TH0/6GU7NiISNsE3Odnrq2abOeHomhscS3Le3izv3HOeuZzoYHktSXRrltef7nsLLNtQRMhiIJ+iPj095Hogn6B+ZWPbP5bEI6+vLWF9Xzob6Muorihf1Vh59I+Mc7h6ivW+E2vJimqtLaKiIaQjsHBQERTJhoMMPF911i38dq5o2vK5m9qF3FvLhb8+P/L+74Ld9D+DKl2SurMO9fsbVnd/wk+2U1sFLfs/P8vrgZ6G4wg933fbWM+8lPnkUfvpBPyRzxUvgtR/3wyzTe6ier4dxPoa64YHP+FCOg+3/E674UyhvWLifIUuGguD8qI0UKTzx8ST37eviZ7vb+a9nOhkcTRAOGcnU8//tXxINUx6L0D8yzmjakNeK4gjr6stYX1fG+vryUyFxXV0ZJUVn9oXw0GiCQ91DHO4Z4nD3EIe6hznUPcjhnmF6h8Zm7B8JGSuWlbByWQkrq0torp5cXlVdSlNVbMF6QIdGExzvj9MRXJd5vD/OyFiSWDRMLBqmJBqmpChESTRM8cTrtG2xohDF4TDRiBENh84q5L9QCoIimfTcr6HlnpmTiExcYzY2MPPfFFXAS98OL3uXH7a7WFIpX9ZHvuGvA3Qp2PoWHwLL6s7++M7Bnh/Czz4Mw90zt4cis0yOUjL5mG1d+nDGiUfns/DwP/mhkS+6AXZ8ZHHfR8k5CoLzozZSpLCNJpI8uL+bnUdOUBINUxGLUBGLUhGLUDntuTwWORWkUinHsb4RWrqGaOkapKV76NTysb74lJ/RVBkjFg0RDvnQEw4ZkSD8RNLWRcO+5/PEsO/t6xwYnXGctXWlrKsrZ11dKWtry1ixrITuwVHaTo7QdmKE1hMjtJ0cofXEMJ0Do1Nmhw0Z1JQVUV7s61JenPaIRSgvDuoZrItFw/QOjfqg1zdKRxD4OvriDIwmZryXZsyYjXY+isIhiiIhomH/nkSD10XhEHUVRXz3HZec+cHJoSBoZlcDn8ffMPfrzrlPTNu+BvgmUI+/Ye7vOudag/W3ASEgCnzROffVuX6WGjnJGYnRqVPxjw7AmssW7h6LZ6qv1ZeraevCH3u4109qNDb8PLcbGJ42acq0mS3Hh6dO6JLuvGv9MNT6cxe+/LLkKAjOj9pIEVloI2NJDnUP0dI9SEvXEM/1DjOW8Lf3GE8Gz8HtPMaTwYQ4SX9rj0TSURGLsK6ujLV1ZawLHmtqS+d9S47RRJL2k/G0kDhM99AYg/EEg6MJBuMJBkYTDI6OMzSaZCA+znhyZv4Jh4z6cn9tZlNljKbg+symqmL/HKwriYYZS6aIj6UYGU8SH08yEjziY0niiSQjwbaR8STjiRTjyRRjE89J//5MPEYT/v0ZT6QoLQ7zmbdceFbnJSeCoJmFgX3Aa4BW4BHgBufc02n7/Bvw7865b5vZVcAfOOd+z8yKgrKNmlk5sAe4zDl37HQ/T42cSJ5IJmaGyWhJ9ialkZykIDg/aiNFRCaNJpKnguLwWJKaMj8Daz5cezif9jGTd8G8GDjgnGsJCnULcB3wdNo+5wMfDJbvAW4HcM6lDwguxvcMikghCEcgXOGvYxQRERFZYMWRMMXlYWrLi7NdlKzKZMBaCRxNe90arEv3JPCmYPmNQIWZ1QKY2Soz2xUc45Oz9Qaa2TvNbKeZ7ezq6lrwCoiIiIiIiOSjbPe0fQi40sweB64E2oAkgHPuqHNuG7AReLuZNU7/x865m51z251z2+vrl8jNzkVERERERLIsk0GwDViV9ro5WHeKc+6Yc+5NzrkXA38VrDs5fR/8NYJXZLCsIiIiIiIiBSOTQfARYJOZrQsmf7keuCN9BzOrM7OJMvwFfgZRzKzZzEqC5WrgcmBvBssqIiIiIiJSMDIWBJ1zCeB9wH8CzwA/cM49ZWY3mtm1wW47gL1mtg9oBG4K1p8H/NrMngTuAz7lnNudqbKKiIiIiIgUkkzOGopz7k7gzmnr/jZt+Vbg1ln+3S+AbZksm4iIiIiISKHK9mQxIiIiIiIissgUBEVERERERAqMgqCIiIiIiEiBURAUEREREREpMOacy3YZFoSZdQFHZtlUB3TP41BVQF8G9s30sVcDz2Xo2LnynkBh1HM+dZzvsXPpPdG5PLtjZ/p3LVfqeTprnHP1Z3mMgrFAbaR+D89u30zvv1TrqbZjJp3LxS9LrtRzcdtH51xeP4Cd89z/5kzsuwjH7lqi5VY9z6KOOVZuncs8OZe5VE89MvuYTxup38PFLXeh1FNth85ljpQlJ+q52O2jhobO9JMM7ZvpY5/M4LFz5T2BwqjnfOo432Pn0nuic3l2x87071qu1FNyh34Pz27fTO+/VOuptmMmncuzP/5Sreeito95MzT0dMxsp3Nue7bLkWmqZ/4ohDpCYdSzEOoIhVPPfFQI564Q6giqZz4phDqC6pkLCqFH8OZsF2CRqJ75oxDqCIVRz0KoIxROPfNRIZy7QqgjqJ75pBDqCKpn1uV9j6CIiIiIiIhMVQg9giIiIiIiIpImr4OgmV1tZnvN7ICZfSTb5ckEMztsZrvN7Akz25nt8iwUM/ummXWa2Z60dTVm9gsz2x88V2ezjAvhNPX8qJm1Bef0CTN7fTbLeLbMbJWZ3WNmT5vZU2b2gWB9Xp3POeqZb+czZma/MbMng3p+LFi/zsx+HXze/quZFWW7rHJ6hdA+gtrIbJbxbBVC+wiF0Uaqfczd9jFvh4aaWRjYB7wGaAUeAW5wzj2d1YItMDM7DGx3zs3nXok5z8xeAQwC33HObQnW/SPQ65z7RPCHS7Vz7sPZLOfZOk09PwoMOuc+lc2yLRQzWw4sd849ZmYVwKPAbwO/Tx6dzznq+Rby63waUOacGzSzKPAg8AHgg8CPnHO3mNlXgSedc1/JZllldoXSPoLayCX+mZr37SMURhup9jF328d87hG8GDjgnGtxzo0BtwDXZblM8gI55+4Heqetvg74drD8bfyHyJJ2mnrmFedcu3PusWB5AHgGWEmenc856plXnDcYvIwGDwdcBdwarF/y5zPPqX1c4gqhjSyE9hEKo41U+5i77WM+B8GVwNG0163k4X86/H+wn5vZo2b2zmwXJsManXPtwfJxoDGbhcmw95nZrmBozJIdDjKdma0FXgz8mjw+n9PqCXl2Ps0sbGZPAJ3AL4CDwEnnXCLYJV8/b/NFobSPoDYyH+XV52m6Qmgj1T7m1udtPgfBQnG5c+4lwDXAe4OhFHnP+THN+TmuGb4CbAAuBNqBT2e3OAvDzMqBHwJ/4pzrT9+WT+dzlnrm3fl0ziWdcxcCzfjepc1ZLpLI6aiNzC9593k6oRDaSLWPuSefg2AbsCrtdXOwLq8459qC507gNvx/unzVEYwznxhv3pnl8mSEc64j+CBJAV8jD85pMFb+h8B3nXM/Clbn3fmcrZ75eD4nOOdOAvcAlwLLzCwSbMrLz9s8UhDtI6iNzHJ5Fly+fp4WQhup9jE328d8DoKPAJuCmXqKgOuBO7JcpgVlZmXBRbeYWRnwWmDP3P9qSbsDeHuw/Hbgx1ksS8ZMfPAH3sgSP6fBxdPfAJ5xzn0mbVNenc/T1TMPz2e9mS0LlkvwE448g2/w/nuw25I/n3ku79tHUBtJHv4O5tvnKRRGG6n2MXfbx7ydNRQgmIb2c0AY+KZz7qYsF2lBmdl6/DecABHge/lSRzP7PrADqAM6gL8Dbgd+AKwGjgBvcc4t6QvJT1PPHfhhEg44DLwr7TqBJcfMLgceAHYDqWD1X+KvD8ib8zlHPW8gv87nNvzF7mH8l4k/cM7dGHwe3QLUAI8Dv+ucG81eSWUu+d4+gtpIlv5nat63j1AYbaTax9xtH/M6CIqIiIiIiMhM+Tw0VERERERERGahICgiIiIiIlJgFARFREREREQKjIKgiIiIiIhIgVEQFBERERERKTAKgiI5wMySZvZE2uMjC3jstWa2pO/NIyIihUttpEhmRJ5/FxFZBCPOuQuzXQgREZEcpDZSJAPUIyiSw8zssJn9o5ntNrPfmNnGYP1aM7vbzHaZ2V1mtjpY32hmt5nZk8HjsuBQYTP7mpk9ZWY/N7OSrFVKRERkAaiNFDk7CoIiuaFk2rCXt6Zt63PObQW+BHwuWPdF4NvOuW3Ad4EvBOu/ANznnHsR8BLgqWD9JuDLzrkLgJPAmzNcHxERkYWiNlIkA8w5l+0yiBQ8Mxt0zpXPsv4wcJVzrsXMosBx51ytmXUDy51z48H6dudcnZl1Ac3OudG0Y6wFfuGc2xS8/jAQdc59PPM1ExEROTtqI0UyQz2CIrnPnWZ5PkbTlpPo+mAREckPaiNFzpCCoEjue2va80PB8q+A64PltwEPBMt3AX8EYGZhM6tarEKKiIhkgdpIkTOkbzxEckOJmT2R9vo/nHMT02NXm9ku/DeWNwTr3g/8s5n9GdAF/EGw/gPAzWb2h/hvNf8IaM946UVERDJHbaRIBugaQZEcFlz/sN05153tsoiIiOQStZEiZ0dDQ0VERERERAqMegRFREREREQKjHoERURERERECoyCoIiIiIiISIFREBQRERERESkwCoIiIiIiIiIFRkFQRERERESkwCgIioiIiIiIFJj/D2GWtwUo8THeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"Model took %0.2f hours to train\"%((end - start)/3600))\n",
    "\n",
    "plot_model_history(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ZcWydmIVhZGr",
    "outputId": "4155982a-83c7-4775-f31f-bcbeaa22309b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 435us/step\n",
      "Test loss: 0.26194198840968314\n",
      "Test accuracy: 0.932\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UE3lF6EH1r_L",
    "outputId": "56ded1ff-0d18-4299-dadd-cc9d7005acea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"DNST_model_weights_s1_v2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Og56VCRh5j8V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Anupam_Kumar_EIP2_Batch2_Assignment_DNST_CIFAR10_AUG_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
